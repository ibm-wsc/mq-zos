{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"IBM MQ for z/OS Enablement for the IBM Washington Systems Center","text":""},{"location":"#at-a-glance","title":"At a glance","text":"<p>This site is a repository for IBM WSC intellectual capital related to IBM MQ for z/OS. It includes labs, presentations, and document materials. To request specific enablement, demonstrations or labs, make a request to your IBM representative to engage the Washington Systems Center.</p>"},{"location":"#other-ibm-mq-resources-not-specific-to-zos","title":"Other IBM MQ resources - not specific to z/OS","text":"<p>IBM Developer - MQ Materials</p> <p>IBM Integration Community Blog</p> <p>IBM Messaging GitHub</p> <p>IBM MQ Documentation</p> <p>IBM MQ Performance</p>"},{"location":"#acknowledgements","title":"Acknowledgements","text":"<p>Contributors to the site include Lyn Elkins, Mitch Johnson, and Dorothy Quincy</p>"},{"location":"archive/","title":"Archive","text":"<p>Assets listed here may be outdated or no longer offered, but we have included them as reference.</p> Asset Author Intro to MQ SMF - Buffer Pool Stats Lyn Elkins Intro to MQ SMF - Buffer Pool Stats pt. 2 Lyn Elkins Intro to MQ SMF Lyn Elkins Intro to MQ SMF - Data gathering Lyn Elkins"},{"location":"archive/#ibm-share-2022-lab-exercises","title":"IBM SHARE 2022 Lab Exercises","text":"Asset Ansible on IBM MQ lab Queue Statistics lab Streaming queues on IBM MQ for multiplatforms Streaming queues on IBM MQ for z/OS"},{"location":"certificates/","title":"Using SSL with MQ","text":""},{"location":"certificates/#audience-level","title":"Audience level","text":"<p>Intermediate or advanced; Users should have an understanding of MQ, RACF, Java, SSL/TLS  </p>"},{"location":"certificates/#skillset","title":"Skillset","text":"<p>z/OS Systems Programming, MQ Administration</p>"},{"location":"certificates/#background","title":"Background","text":"<p>IBM MQ for z/OS customers are continually looking for methods to keep their environments secure. Understanding how to use SSL/TLS with z/OS is critical to keeping up with encryption requirements. In this lab, you will set up the infrastructure for certificates in a IBM MQ environment and implemented SSL security between MQ Explorer and a z/OS queue manager.</p>"},{"location":"certificates/#overview-of-exercise","title":"Overview of exercise","text":"<p>In the first part of this exercise, we will generate a self-signed certificate connecting z/OS to our client. This step is necessary to create the TLS infrastructure to be used for channel encryption. </p> <p>We will do this by generating a certificate authority and personal certificate on z/OS using the RACF Certificate Authority, then we will export the certificate as a trusted certificate to our client, then we will configure a java keystore on our client-side, generate a personal certificate on the client-side and sign the client's personal certificate using our z/OS certificate authority. </p> <p>Please note: self-signed certificates should only be used in lab or test environments. They should not be used in production environments.</p> <p>In the second part of this exercise, we will implement channel encryption to securely connect to a sample queue manager running on z/OS. We will do this by adjusting settings on our queue manager, mainly using MQ Explorer.</p>"},{"location":"certificates/#lab-begin","title":"Lab begin","text":""},{"location":"certificates/#i-set-up-the-zos-side","title":"I. Set up the z/OS side","text":"<ol> <li> <p>Use the TSO command RACDCERT CERTAUTH GENCERT command to create a signer certificate with label 'MQ CA'.</p> <pre><code>racdcert certauth gencert subjectsdn(CN('MQ CA') OU('ATS')\nO('IBM') C('US')) withlabel('MQ CA') keyusage(certsign)\nnotafter(date(2029/12/31)) \n</code></pre> Parameter Meaning subjectsdn(CN('common-name') OU('organizational-unit-name1') O('organization-name') C('country')) Specifies the subject's X.509 distinguished name, which consists of the following components: CommonName - specified with the CN subkeyword. Organizational Unit - specified with the OU subkeyword. Multiple values can be specified for the organizational unit. Country - specified with the C subkeyword. withlabel Specifies the label assigned to this certificate. If specified, this must be unique to the user ID with which the certificate is associated. If not specified, it defaults in the same manner as the WITHLABEL keyword on the RACDCERT ADD command. signwith Specifies the certificate with a private key that is signing the certificate. If SIGNWITH is specified, it must refer to a certificate that has a private key associated with it. If no private key is associated with the certificate, an informational message is issued and processing stops. notafter Specifies the local date and time after which the certificate is no longer valid </li> <li> <p>Use the RACDCERT CERTAUTH GENCERT command to create a personal certificate for the MQ channel initiator (CHIN) with a label of 'MQCHIN'.</p> <pre><code>racdcert id(SYSPROG) gencert subjectsdn(CN('MQ CHIN') OU('ATS')\nO('IBM') C('US')) withlabel('MQ CHIN') signwith(certauth\nlabel('MQ CA')) notafter(date(2029/12/31) \n</code></pre> </li> </ol> Parameter Meaning subjectsdn Specifies the subject's X.509 distinguished name, which consists of the following components: CommonName - specified with the CN subkeyword. Organizational Unit - specified with the OU subkeyword. Multiple values can be specified for the organizational unit. Country - specified with the C subkeyword. withlabel Specifies the label assigned to this certificate. If specified, this must be unique to the user ID with which the certificate is associated. If not specified, it defaults in the same manner as the WITHLABEL keyword on the RACDCERT ADD command. signwith Specifies the certificate with a private key that is signing the certificate. If SIGNWITH is specified, it must refer to a certificate that has a private key associated with it. If no private key is associated with the certificate, an informational message is issued and processing stops. notafter Specifies the local date and time after which the certificate is no longer valid. <p>Tech-Tip: SYSPROG is the MQ channel initiator region\u2019s RACF identity under which the CHIN started task is executing.</p> <p>3.    Run the command </p> <pre><code>    racdcert certauth list(label('MQ CA'))\n</code></pre> <p>Your output should look like this:</p> <pre><code>    Digital certificate information for CERTAUTH:\n\n    Label: MQ CA                                          \n    Certificate ID: 2QiJmZmDhZmjgdTYQMPB                  \n    Status: TRUST                                         \n    Start Date: 2025/03/10 00:00:00                       \n    End Date:   2025/03/31 23:59:59                       \n    Serial Number:                                        \n            &gt;00&lt;                                             \n    Issuer's Name:                                        \n            &gt;CN=MQ CA.OU=ATS.O=IBM.C=US&lt;                     \n    Subject's Name:                                       \n            &gt;CN=MQ CA.OU=ATS.O=IBM.C=US&lt;                     \n    Signing Algorithm: sha256RSA                          \n    Key Usage: CERTSIGN                                   \n    Key Type: RSA                                         \n    Key Size: 2048                                        \n    Private Key: YES\n</code></pre> <p>Tech-Tip: The common name (CN), organization unite(OU), organization(O) country (C) , labels and aliases are case sensitive. Subsequent RACF or keytool commands referencing a label, an alias or common name, etc. in any command must use the exact same case and spacing when referring to the values of these fields in the certificate (i.e. be consistent).</p> <p>For example, command racdcert certauth list(label(\u2018MQ CA\u2019)) would display this certificate while command racdcert certauth list(label(\u2018mq CA\u2019)) would not. Command racdcert certauth delete(label(\u2018MQ CA\u2019)) could be used to delete this certificate while command racdcert certauth delete(label(\u2018mq CA\u2019)) could not.</p> <p>4. Use the RACDCERT ADDRING command to create a RACF Key Ring for the MQ CHIN region\u2019s RACF identity. The signer certificates and WMQ\u2019s personal certificates will be connected to this key ring.</p> <pre><code>    racdcert id(user1) addring(MQCHIN.KeyRing)\n</code></pre> <p>Tech-Tip: RACF key rings are case sensitive so be sure to enter the key ring name, e.g. MQ.KeyRing in exactly the same case in subsequent commands.</p> <p>Tech-Tip: SYSPROG needs READ access to FACILITY resource IRR.DIGTCERT.LISTRING in order to access this key ring.</p> <p>5. Use the RACDCERT CONNECT command to connect the MQ signer certificate that was used to sign the \u2018MQ CA\u2019 client\u2019s personal certificate to the MQ CHIN\u2019s key ring.</p> <pre><code>    racdcert id(SYSPROG) connect(ring(MQCHIN.KeyRing) label('MQ CA') certauth usage(certauth))\n</code></pre> <p>Tech-Tip: A RACF key ring is unique to the owning user. So connecting a signer certificate labeled \u201cMQ CA\u201d with command RACDCERT ID(USER1) CONNECT(RING(MQCHIN.KeyRing) has no effect on a key ring labeled MQCHIN.KeyRing owned by user USER2.</p> <p>6. Use the RACDCERT CONNECT command to connect the MQ CHIN region's persional certificate to the MQCHIN.KeyRing. </p> <pre><code>    racdcert id(SYSPROG) connect(ring(MQCHIN.KeyRing) label('MQ CHIN') default)\n</code></pre> <p>Tech-Tip: The default parameter indicates that this is the personal certificate that will be provided to the remote application during a connection request.</p> <p>7. Use the RACF RACDCERT LISTRING command to display the MQCHIN.KeyRing contents</p> <pre><code>    racdcert id(SYSPROG) listring(MQCHIN.KeyRing)\n</code></pre> <p>8. The MQ signer certificate needs to be exported and installed in the client's trust stores. Use the RACDCERT CERTAUTH EXPORT command to export the MQ signer certificate from RACF into a sequential dataset.</p> <pre><code>    racdcert certauth export(label('MQ CA')) dsn(mq.cacert.cer)\n</code></pre>"},{"location":"certificates/#ii-configuring-the-mq-explorer-ssl-support","title":"II. Configuring the MQ Explorer SSL Support","text":"<ol> <li> <p>Open a command window and enter the following:</p> <pre><code>user1@129.40.114.132's password:\nConnected to 129.40.114.132.\nsftp&gt; cd //'USER1'\nsftp&gt; ls /+mode=text\n/+mode=text\nsftp&gt; get MQ.CACERT.CER\nFetching //USER1/MQ.CACERT.CER to MQ.CACERT.CER\n</code></pre> </li> <li> <p>Import the MQ Certificate Authority certificate using the keytool import command to import the signer certificate into local trust store file(e.g. USER1.jks) and indicate that this is a trusted signer certificates (-trustcacerts)</p> <pre><code>keytool -import -v -trustcacerts -alias \"MQ CA\" -file MQ.CACERT.CER -keystore USER1.jks\n</code></pre> </li> <li> <p>Use the keytool genkey command to generate a self-signed certificate with the desired distinguished name specification. This is required in order to generate a certificate request that will be sent to RACF for signing by the MQ CA certificate.</p> <pre><code>keytool -genkey -alias \"USER1\" -dname \"CN=USER1, OU=ATS, O=IBM, C=US\" -keystore USER1jks -keyalg RSA\n</code></pre> </li> <li> <p>Use the keytool certreq command to extraact the self-signed certificate to a certificate request file that can be uploaded to z/OS.</p> <pre><code>keytool -certreq -alias \"USER1\" -file certreq.cer -keystore USER1.jks\n</code></pre> </li> <li> <p>Use ftp to move the certificate request to z/OS.</p> <pre><code>user1@129.40.114.132's password:\nConnected to 129.40.114.132.\nsftp&gt; cd //'USER1'\nsftp&gt; ls /+lrecl=256,recfm=vb,blksize=0\n/+lrecl=256,recfm=vb,blksize=0\nsftp&gt; mput certreq.cer\n</code></pre> </li> <li> <p>Browse USER1.CERTREQ.CER and you should see something like this below:</p> <pre><code>---------BEGIN NEW CERTIFICATE REQUEST----------\nJASKHUGSIteusheughaoer8hoiueahgkshrekughkurehgr\n...\n----------END NEW CERTIFICATE REQUEST-----------\n</code></pre> </li> <li> <p>After uploading the certificate request to z/OS, use the RACDCERT GENCERT command to sign the certificate request with the RACF MQ signer certificate and associate this certificate with a valid RACF identity (e.g. USER1).</p> <p>racdcert id(USER1) gencert(certreq.cer) withlabel('USER1') signwith(certauth label('MQ CA')) notafter(date(2029/12/31))</p> </li> <li> <p>Export the signed client certificate request file to a sequential z/OS dataset using the RACDCERT EXPORT command.</p> <p>racdcert id(USER1) export(label('USER1')) dsn(cert.cer)</p> </li> <li> <p>Browse USER1.CERT.CER and you should see something like below:</p> <pre><code>-------BEGIN CERTIFICATE --------\nADSUHFAKURENJJLANFJLRELUGNAJKFNVA\n...\n------END CERTIFICATE------------\n</code></pre> </li> <li> <p>Use ftp to move the signed certificate in dataset USER1.CERT.CER to Windows</p> <pre><code>user1@129.40.114.132's password:\nConnected to 129.40.114.132.\nsftp&gt; cd //'USER1'\nsftp&gt; ls /+mode=text\n/+mode=text\nsftp&gt; get USER1.CACERT.CER\nFetching //USER1/CERT.CER to USER1.CERT.CER\n</code></pre> </li> <li> <p>Use the keytool -import command to import the signed certificate into the JSSE keystore.</p> <pre><code>keytool -v -import -alias \"USER1\" -file CERT.CER -keystore USER1.jks\n</code></pre> </li> </ol> <p>Tech-tip If the message \u201cCertificate reply was installed in keystore\u201d is not displayed then there was problem somewhere in this process. Steps 2 to 12 could repeated after removing file user1.jks and deleting the USER1 certificate with command racdcert id(USER1) delete(label('USER1')</p> <p>12. To recap, in this part of the exercise, we configured a self-signed certificate.</p> <p></p>"},{"location":"certificates/#iii-configure-channel-encryption","title":"III. Configure channel encryption","text":"<p>1. At this point, we have to adjust queue manager settings for our z/OS queue manager ZQS1. Start by opening MQ Explorer.</p> <p>2. Modify RACF key ring (SSLKEYR) to be accessed for personal and certificate authority digital certificates</p> <pre><code>    /ZQS1 ALTER QMGR SSLKEYR('MQCHIN.KeyRing')\n</code></pre> <p>3. Modify the number of SSL sub tasks (SSLTASKS) for processing SSL calls</p> <pre><code>    /ZQS1 ALTER QMGR SSLTASKS(5)\n</code></pre> <p>4. Restart CHINIT address space</p> <pre><code>    /ZQS1 STOP CHINIT\n    /ZQS1 START CHINIT\n</code></pre> <p>5. Start MQ Explorer on your desktop. Click on Window on the tool bar and then click on Preferences. Expand the MQ Explorer option and then expand Client Connections. Select SSL Key Repositories preferences. Check the box beside 'Enable default SSL key repositories' and then use the 'Browse' buttons to select the key store configured earlier in this exercise (e.g. USER1.jks) for both for Trusted Certificates and Personal Certificates store files. Use the Enter password button to enter the password for both store files.</p> <p></p> <p>6. Click Apply and Close to continue.</p> <p>7. Switch to the SSL Options preference window. Check the box beside 'Enable default SSL options' and then use the pull down to select a SSL CipherSpec of ECDHE_RSA_AES_128_CBC_SHA256. Click 'Apply' and 'Close' to continue.</p> <p></p> <p>Tech-Tip: Which cipher suite selected is not important as long as the same cipher is used consistently. </p> <p>8. Using an existing non-SSL connection to QMZ1, create a new server connection channel by selecting 'Channels' and right-clicking 'Select New' -&gt; Server-connection Channel'. Enter a nameof USER1.SSL.SVRCONN and click 'Next' to continue.</p> <p>9. On the 'New Server-connection Channel' window, select 'SSL' and use the pull down arrow to select ECDHE_RSA_AES_128_CBC_SHA256 as the SSL CipherSpec. Select 'General' to continue.</p> <p></p> <p>10. On the General window use the pull-down arrow to select TCP. Click Finish to continue.</p> <p></p> <p>11. Next a Channel Authentication record needs to be added to allow access to the USER1.SSL.SVRCONN channel. Using a non-SSL connection to ZQS1, expand 'Channels' and select 'Channel Authentication Records'. </p> <p></p> <p>12. Right-click and select 'New -&gt; Channel Authentication Record' to display the 'New Channel Authentication Record \u2013 Create a Channel Authentication Record' window. Take the default for the 'Rule' type (Allow access) and press 'Next' to continue.</p> <p></p> <p>13. On the 'Match' part of the identity window, select the radio button by 'SSL/TLS Distinguished Name'. Click 'Next' to continue.</p> <p></p> <p>14. On the 'Matching the channels window', enter USER1.SSL.* in the area under Channel Profile. Press 'Next' to continue.</p> <p></p> <p>15. On the Matching SSL/TLS Distinguished Names window enter 'OU=ATS' as the SSL/TLS subject\u2019s Distinguished Name pattern and 'CN=MQ CA,OU=ATS,O=IBM,C=US' as the SSL/TLS issuer\u2019s Distinguished Name pattern. Enter an asterisk (*) for the IP address or hostname pattern. Click Next to continue. </p> <p></p> <p>16. On the Authorization user ID window click the radio button beside 'Fixed user ID' and enter 'USER1' as the 'User ID'. Press 'Next' 3 times to continue. </p> <p></p> <p>17. Click 'Finish' on the Summary window to complete the definition of this authentication rule. </p> <p></p> <p>18. Next, create a new remote connection to queue manager ZQS1.</p> <p></p> <p>19. On the 'Specify new connection details' window, enter the appropriate z/OS LPAR IP address as the 'Host name', 1424 as the 'Port Number' and USER1.SSL.SVRCONN as the 'Server-connection channel' name. Click Next 3 times to continue. </p> <p></p> <p>20. On the 'Specify SSL certificate key repository details' window, ensure the box beside 'Enable SSL key repositories' is checked. If the 'Trusted Certificate Store' is not configured, use the 'Browse' and 'Enter' password buttons to provide this information. Click 'Finish' to continue.</p> <p></p> <p>21. You should now be connected to the queue manager using SSL. To confirm enter this MVS command:</p> <pre><code>    ZQS1 display chstatus(USER1.*) mcauser sslcertu\n</code></pre> <p>The RACF identity associated with the client\u2019s certificate is displayed in the SSLCERTU property</p> <pre><code> CSQM201I ZQS1 CSQMDRTC  DISPLAY CHSTATUS DETAILS 610               \n CHSTATUS(USER1.SSL.SVRCONN)                                        \n CHLDISP(PRIVATE)                                                   \n CONNAME(9.31.118.212)                                              \n CURRENT                                                            \n CHLTYPE(SVRCONN)                                                   \n STATUS(RUNNING)                                                    \n SUBSTATE()                                                         \n STOPREQ(NO)                                                        \n RAPPLTAG(MQ Explorer 9.4.1)                                        \n SSLCERTU(SYSPROG)                                                  \n MCAUSER(USER1)                                              \n  END CHSTATUS DETAILS   \n</code></pre> <p>As a test, add and delete queues and other functions that only USER1 should have authority to perform.</p> <p>22. CONGRATULATIONS!!! You have configured self-signed certificates and implemented SSL security between MQ Explorer and the queue manager. </p>"},{"location":"comparing-offloading/","title":"Lab Exercise: Comparing SMDS and DB2 Blobs for queue-sharing","text":""},{"location":"comparing-offloading/#audience-level-knowledge-of-mq-or-zos","title":"Audience level: knowledge of MQ or z/OS","text":""},{"location":"comparing-offloading/#skillset-zos-systems-programming-mq-administration","title":"Skillset: z/OS Systems Programming, MQ Administration","text":""},{"location":"comparing-offloading/#background","title":"Background","text":"<p>Shared message data sets (SMDS) are the preferred method for offloading large messages in queue-sharing groups. SMDS\u2019s are designed to handle large messages efficiently, so in this exercise, we will test two CF structures, one with SMDS and the other with BLOBs to examine the differences between the two offloading mechanisms.</p>"},{"location":"comparing-offloading/#overview-of-exercise","title":"Overview of exercise","text":"<p>I.  Run OEMPUT program against SMDS-enabled CF structure (TEST1)</p> <p>II. Run OEMPUT program against BLOB-enabled CF structure (TEST2)</p> <p>III.    Compare the output from both</p>"},{"location":"comparing-offloading/#steps-of-exercise","title":"Steps of exercise","text":""},{"location":"comparing-offloading/#i-run-oemput-program-against-smds-enabled-cf-structure-test1","title":"I. Run OEMPUT program against SMDS-enabled CF structure (TEST1)","text":"<ol> <li> <p>Using MQ Explorer, verify that the below configuration is in place. You should see connections to ZQS1, ZQS2, and you should see a QSGA queue-sharing group visible.</p> </li> <li> <p>In MQ Explorer, navigate to the queue-sharing group QSGA\u2019s Coupling Facility Structures by clicking  \u2018&gt;\u2019 next to the QSGA label then pressing Coupling Facility Structures to display more information.</p> </li> <li> <p>Your structures should look like the following:     </p> </li> <li> <p>Scroll to the right, making sure that all offload rules are the same for TEST1 and TEST2 except for the \u2018Offload\u2019 and \u2018Group data set name\u2019 fields.</p> <p></p> </li> <li> <p>Now, navigate to the MQS1 z/OS image.</p> </li> <li> <p>Use option 3.4 to navigate to the ZQS1.MQ.JCL data set. Navigate to PUTSMDS and type an \u2018e\u2019 to edit the member.</p> <p></p> </li> <li> <p>In PUTSMDS, you will see an execution of OEMPUT. This JCL puts a large amount of large messages on our SMDS.QUEUE, defined to TEST1. Which parameters are we using with OEMPUT here?</p> </li> </ol> Parameter Description - mZQS1 Specify target queue manager -qSMDS.QUEUE Specify target queue -fileDD:MSGIN Specify messages to be used -ts500 Specify how long message stream should last (500 seconds) -s650000 Specify the size of the message, note we are using a message larger than 63KB here, as to necessitate the use of offloading, since large messages can\u2019t be held in the CF list structures. -l10 Loop MQPUT and MQGET 10 times during execution -cgcpc Mimic client application program by procressing a commit after both MQPUTs and MQGETs -crlf Each line in the input message file is used in sequence as message data -rSMDS.QUEUE Reply-to-queue from which replies will be retrieved (MQGET). If the -r option is omitted, MQGETs will not be issued. <p>**Note: If we specified persistent messages here, the contrast between SMDS and BLOBs would be less noticeable because transactions on both sides would have to wait on logging.</p> <ol> <li>Type \u2018submit\u2019 in the command line and press your enter key. You should see a reason code (RC) of 0000. This execution will take a few minutes to complete.</li> </ol>"},{"location":"comparing-offloading/#ii-run-oemput-program-against-blob-enabled-cf-structure-test2","title":"II. Run OEMPUT program against BLOB-enabled CF structure (TEST2)","text":"<ol> <li> <p>Now, we will repeat the steps to submit another execution of OEMPUT, this time for our queue tied to BLOB storage. </p> </li> <li> <p>Use F3 to back out to the ZQS1.MQ.JCL data set. Place an \u2018E\u2019 next to PUTBLOB and press enter to edit the member. </p> </li> <li> <p>As you look through PUTBLOB, navigating up and down the screen using the F7 and F8 keys, you will notice that the only difference between PUTSMDS and PUTBLOB is the queue name. We are keep all other variables constant, especially message size.</p> </li> <li> <p>Type \u2018submit\u2019 in the command line and press your enter key. You should see a reason code (RC) of 0000. This execution will take a few minutes to complete. </p> </li> </ol>"},{"location":"comparing-offloading/#iii-compare-the-output-from-both","title":"III. Compare the output from both","text":"<ol> <li> <p>From the ISPF main menu, type \u2018sdsf\u2019 or \u2018d\u2019 on the command line and press enter to access the SDSF menu. </p> </li> <li> <p>Here, type \u2018ST\u2019 on the command line and press enter to access the status of recent jobs.</p> </li> <li> <p>In our JCL, our OEMPUT jobs were named OEMPSMDS and OEMBLOB, respectively. We can search for all jobs beginning with OEM, but typing in the command line \u2018pre OEM*\u2019 and pressing enter.</p> </li> <li> <p>Both jobs should appear in a list. Let\u2019s look at OEMPSMDS first. Place a question mark to the left of the job name and press enter. </p> </li> <li> <p>A list should appear with output on how successful the job was and any output from the job. We are interested in the SYSPRINT output. Place a \u2018s\u2019 to the left of SYSPRINT and press enter.</p> </li> <li> <p>Scroll down on the SYSPRINT output until you see the following output. Make not of the Total Transaction value, the Transaction Rate value, and the Avg App CPU per msg value. This gives us information about how many transactions were completed in the allotted time with SMDS storage specified, the efficiency of those transactions, and the CPU consumption required.</p> </li> </ol> <p>If you are unable to see the SYSPRINT screen for any reason, we have prepared sample examples at the end of this lab for reference.</p> <ol> <li> <p>Now, let\u2019s check out the same information for BLOB storage. Use F3 to back out twice until you reach the list containing OEMPSMDS and OEMPBLOB.</p> </li> <li> <p>Place a \u2018?\u2019 next to the OEMPBLOB job and press enter.</p> </li> <li> <p>Place a \u2018s\u2019 next to the SYSPRINT output and press enter.</p> </li> <li> <p>Navigate until you see the Total Transaction value, the Transaction Rate value, and the Avg App CPU per msg value.</p> </li> </ol> <p>If you are unable to see the SYSPRINT screen for any reason, we have prepared sample examples at the end of this lab for reference.</p> <ol> <li>You have now compared the performance and storage consumption of SMDS and BLOB offloading in our test environment! Hopefully, this helps you see the advantages of using SMDS in terms of throughput. While CPU consumption is higher for SMDS in this test environment, </li> </ol> <p>Figure 1. SMDS performance</p> <p></p> <p>Figure 2 BLOB performance</p> <p></p>"},{"location":"connectivity/","title":"Connecting to your z/OS Sysplex MQS1","text":""},{"location":"connectivity/#audience-level","title":"Audience level","text":"<p>Some knowledge of MQ or z/OS </p>"},{"location":"connectivity/#skillset","title":"Skillset","text":"<p>z/OS Systems Programming, MQ Administration \u2003</p>"},{"location":"connectivity/#introduction","title":"Introduction","text":"<p>This lab is designed to connect the user to the Sysplex they have been assigned.  It will cover a couple of different connections (PCOMM, MQ Explorer) and some basic queue manager commands. </p>"},{"location":"connectivity/#lab-steps","title":"Lab Steps","text":"<p>1)  If you have not already done so, please connect to the browser instance you were assigned.  Note that your user ID is always Administrator and the password is associated with the unique URL.  </p> <p>2)  Please look on the panel for a PCOMM connection symbol (  ) labeled \u2018MQS1\u2019 or \u2018MQS2.\u2019   If you do not see it, please follow these steps to get it added: a.  From the Windows programs, please expand the IBM Personal Communications group and select \u2018Start or Configure Sessions\u2019 as shown here:</p> <p></p> <p>b.  Some of our Windows images do not have the correct directory for PCOMM sessions.  If the Session Manager pane comes up empty, please change the directory that PCOMM uses. </p> <p>i.  In the upper left had corner of the Session manager pane, please chose \u2018File\u2019 then Change Directory </p> <p></p> <p>ii. Select the Documents directory</p> <p></p> <p>iii.    If you see the MQS1 \u2018WS\u2019 file, please click on \u2018Open\u2019 as shown. </p> <p></p> <p>iv. IF you do not see the \u2018mqs1.WS\u2019 file, please notify Dorothy or Lyn immediately.  We may need to reset your image. </p> <p>v.  If you do see the file, after clicking on Open, your \u2018Session Manager\u2019 pane should look something like this:</p> <p>c.  Highlight \u2018mqs1\u2019 and click on the \u2018Start\u2019 button.</p> <p>3)  If you do see the \u2018mqs1\u2019 icon, please click on it.</p> <p>4)  At this point the WSC MQPLEX1 should be shown.  It may take a minute or so to connect. </p> <p>5)  Enter \u2018mqs1 user1\u2019 and press the enter key (note it may be the right hand \u2018ctrl\u2019 key or the actual enter key depending on your keyboard map.  If you would like to change the enter key and do not know how to alter your keyboard, please ask Dorothy or Lyn for assistance. </p> <p>6)  At this point you should see the TSO logon screen.  Please use the enter key to take you to the ISPF manu.</p> <p>7)  The menu looks as follows:</p> <p>8)  You have now successfully connected to the Sysplex LPAR MQS1!  </p> <p>9)  Check to see if the queue manager is running: a.  On the \u2018Option\u2019 line, please enter 13 to navigate to the z/OS User panel. b.  Then enter \u201814\u2019 to select SDSF</p> <p>c.  From the SDSF menu, please select DA and as a convenience change the \u2018scroll\u2019 value from Page to CSR (cursor position) as shown.</p> <p>d.  Enter the command \u2018f ZSQ1\u2019 to search for the queue manager as shown:</p> <p>e.  If the response is  , then the queue manager is not started yet. f.  To start the queue manager, enter the start command as shown:</p> <p>Note that the command prefix for our queue managers is the queue manager name only, we don\u2019t use special characters for these.  g.  You should bet a \u2018NO RESPONSE RECEIVED\u2019 replay, then do a search for ZQS1 again.</p> <p>h.  The started queue manager should then show up in the \u2018Active Users\u2019 list, as seen here: </p> <p>i.  Next, start the channel initiator address space by entering   \\ The response should be: </p> <p>j.  Using the enter key, the CHIN should now show up in the active users list:</p> <p>10) Now that the queue manager and channel initiator have started, it is time to connect the MQ Explorer to the queue manager.  Return to the windows image, Click on the  MQ Explorer as shown here: </p> <p>11) The MQ Explorer panel should look something like this:</p> <p>12) Notice that there is no entry for ZQS1, so we need to add a connection to that queue manager.  To do this, right click on the Queue Managers folder and select \u2018Add remote queue manager.\u2019 13) The \u2018Add queue manager\u2019 pane should appear.  Please fill in the queue manager name ZQS1 \u2013 CASE MATTERS! Then please click on the Next button.</p> <p>14) On the Specify new connection details panel, enter the host name as clone1mqs1 and the port number as 1424 as shown.  Please then click on the \u2018Finish\u2019 button.  </p> <p>The name clone1mqs1 has been created in the etc hosts file for convenience.  </p> <p>IF you have trouble connecting, please ask Dorothy and Lyn for assistance.  </p> <p>15) The queue managers panel is displayed showing the new queue manager, and a new folder for the Queue Sharing Group.  Expanding that folder will show the queue sharing group resources.  </p> <p>Congratulations!  Your Windows image is now fully connected to the back end Sysplex. </p>"},{"location":"kafka-client/","title":"Connecting IBM MQ for z/OS to Kafka as a client","text":""},{"location":"kafka-client/#audience-level","title":"Audience level","text":"<p>Knowledge of IBM MQ for z/OS or Linux</p>"},{"location":"kafka-client/#skill-set","title":"Skill set","text":"<p>Kafka, IBM MQ for z/OS</p>"},{"location":"kafka-client/#background","title":"Background","text":"<p>This lab is designed for MQ administrators looking to gain beginner experience with Apache Kafka. If you are looking to gain familiarity with connecting IBM MQ for z/OS to Kafka for event-streaming, this lab is a great place to start. In this lab, we will walk through configuring the open-source Kafka Connector to demonstrate how to capture z/OS events with a standalone Kafka instance. Businesses are looking to capture the valuable insights on z/OS with events, using Kafka. As an MQ administrator, this lab will help you become comfortable with the Kafka architecture. This lab is for development and test purposes only.</p> <p>If you have a license for IBM MQ for z/OS Advanced or Advanced VUE or IBM Event Streams, you have fully supported access to the MQ-Kafka connectors. </p>"},{"location":"kafka-client/#high-level-architecture","title":"High-level architecture","text":""},{"location":"kafka-client/#pre-requisities","title":"Pre-requisities","text":"<ol> <li> <p>Java running on Windows Subsystem for Linux</p> <pre><code>openjdk version \"21.0.6\" 2025-01-21\nOpenJDK Runtime Environment (build 21.0.6+7-Ubuntu-122.04.1)\nOpenJDK 64-Bit Server VM (build 21.0.6+7-Ubuntu-122.04.1, mixed mode, sharing)\n</code></pre> </li> <li> <p>Apache Maven running on Windows Subsystem for Linux</p> <pre><code>Apache Maven 3.6.3\nMaven home: /usr/share/maven\nJava version: 21.0.6, vendor: Ubuntu, runtime: /usr/lib/jvm/java-21-openjdk-amd64\nDefault locale: en, platform encoding: UTF-8\nOS name: \"linux\", version: \"5.15.167.4-microsoft-standard-wsl2\", arch: \"amd64\", family: \"unix\"\n</code></pre> </li> <li> <p>Apache Kafka downloaded from here in binary format from (I am using kafka_2.13-3.9.0)</p> </li> <li> <p>IBM MQ for z/OS. I am using IBM MQ version 9.4. You must use a version of MQ beyond v.8.</p> </li> </ol>"},{"location":"kafka-client/#lab-overview","title":"Lab Overview","text":"<p>I. Configure MQ objects II. Prepare your Kafka server and topic II. Run the MQ-Kafka source connector III. Send messages from MQ to Kafka IV. Stopping Apache Kafka</p>"},{"location":"kafka-client/#lab-begin","title":"Lab Begin","text":""},{"location":"kafka-client/#i-configure-your-mq-objects","title":"I. Configure your MQ objects","text":"<p>In this step, we will create the necessary MQ objects to send messages from MQ to our Kafka client.</p> <ol> <li> <p>In order to send messages from MQ to Kafka, we need to set up a queue and a channel on MQ. On the MQ Web Console or MQ Explorer, create a local queue called KAFKA.QUEUE.</p> </li> <li> <p>On the MQ Web Console or MQ Explorer, create a server-connection channel called KAFKA.SVRCONN.</p> </li> </ol>"},{"location":"kafka-client/#ii-prepare-your-kafka-server-and-topic","title":"II. Prepare your Kafka server and topic","text":"<p>In this step, we will start the Kafka server and create our first topic. </p> <p>1. Navigate to your linux distro on your local machine. This example assumes the use of Ubuntu.</p> <p>2. Start a ZooKeeper server:     <pre><code>bin/zookeeper-server-start.sh config/zookeeper.properties\n</code></pre></p> <pre><code>You will see a long list of messages, including the Zookeeper logo.\n</code></pre> <p>3. In another terminal, start a Kafka server:     <pre><code>bin/kafka-server-start.sh config/server.properties\n</code></pre></p> <pre><code>You will see a long list of messages.\n</code></pre> <p>4. In a third terminal window, create a topic called <code>TSOURCE</code> for the connector to send events to:     <pre><code>bin/kafka-topics.sh --zookeeper localhost:2181  --create --topic TSOURCE --partitions 1 --replication-factor 1\n</code></pre></p> <p>5. At this point, you have a Kafka cluster consisting of a single node.</p> <p>The configuration is as follows: * Kafka bootstrap server - <code>localhost:9092</code> * ZooKeeper server - <code>localhost:2181</code> * Topic name - <code>TSOURCE</code></p> <p>Note: This configuration of Kafka puts its data in <code>/tmp/kafka-logs</code>, while ZooKeeper uses <code>/tmp/zookeeper</code> and Kafka Connect uses <code>/tmp/connect.offsets</code>. You can clear out these directories to reset to an empty state, making sure beforehand that they're not being used for something else. Use kafka-logs to navigate error-handling</p>"},{"location":"kafka-client/#iii-running-the-mq-source-connector","title":"III. Running the MQ source connector","text":"<p>The MQ source connector takes messages from an MQ queue and transfers them to a Kafka topic.</p> <p>1. In a directory of your choice, clone and build the connector:</p> <pre><code>git clone https://github.com/ibm-messaging/kafka-connect-mq-source.git\ncd kafka-connect-mq-source\nmvn clean package\n</code></pre> <p>Going forward, we'll refer to the top-level directory you used to build the connector as the connector root directory.</p> <p>2. In a terminal window, change directory into the connector root directory and copy the sample connector configuration file into your home directory so you can edit it safely:     <pre><code>cp config/mq-source.properties ~\n</code></pre></p> <p>3. Edit the following properties in the <code>~/kafka-connect-mq-source/mq-source.properties</code> file to match the configuration so far:    <pre><code>topic=TSOURCE\nmq.queue.manager=ZQS1\nmq.connection.name.list=localhost(1414)\nmq.channel.name=KAFKA.SVRCONN\nmq.queue=KAFKA.QUEUE\n</code></pre></p> <p>4. You will also have to modify <code>/config/connect-standalone.properties</code> in your Kafka root directory. The last line should reflect the location of your connector root directory.     <pre><code>plugin.path=~/kafka-connect-mq-source\n</code></pre></p> <p>Note: You may notice here the use of one queue manager could inhibit high availability. This is because we are running the connector in standalone mode. To achieve higher availability, you would either want to use shared queues in your MQ configuration or run the connector in distributed mode. Distributed mode is beyond the scope of this tutorial.</p> <p>4. Change directory to the Kafka root directory. Start the connector worker replacing <code>&lt;connector-root-directory&gt;</code> and <code>&lt;version&gt;</code> with your directory and the connector version:</p> <pre><code>``` shell\nCLASSPATH=&lt;connector-root-directory&gt;/target/kafka-connect-mq-source-&lt;version&gt;-jar-with-dependencies.jar bin/connect-standalone.sh config/connect-standalone.properties ~/mq-source.properties\n```\n\nThe log output will include the following messages that indicate the connector worker has started and successfully connected to IBM MQ:\n\n```\nINFO Created connector mq-source\nINFO Connection to MQ established\n```\n</code></pre> <p>Note: We are running our connector in standalone mode here for simplicity. </p> <p>5. Once the connector has started successfully and connected to MQ, you'll see this message:</p> <pre><code>INFO Connection to MQ established\n</code></pre> <p>You should also be able to see your KAFKA.QUEUE on MQ with the open input field as 1. </p>"},{"location":"kafka-client/#iv-send-messages-from-mq-to-kafka","title":"IV. Send messages from MQ to Kafka","text":"<p>1. In a new terminal window, use the Kafka console consumer to start consuming messages from your topic and print them to the console: <pre><code>bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic TSOURCE\n</code></pre></p> <p>2. Now, from either the MQ Web Console or MQ Explorer, go ahead and put some test messages on your queue. After a short delay, you should see the messages printed by the Kafka console consumer.</p> <p>Congratulations! The messages were transferred from the MQ queue <code>KAFKA.QUEUE</code> onto the Kafka topic <code>TSOURCE</code>.</p>"},{"location":"kafka-client/#v-stopping-apache-kafka","title":"v. Stopping Apache Kafka","text":"<p>To shut down your work cleanly, in the Kafka root directory, stop Kafka and ZooKeeper:</p> <pre><code>bin/kafka-server-stop.sh\nbin/zookeeper-server-stop.sh\n</code></pre> <p>Note: Make sure Kafka is fully stopped before stopping ZooKeeper.</p>"},{"location":"kafka-client/#what-could-go-wrong-error-handling","title":"What could go wrong? Error handling","text":"<ul> <li> <p>You may have to alter the defaults in config/server.properties. The location of your log should reflect a useful path for your own environment. As an example:  </p> <pre><code># A comma separated list of directories under which to store log files\nlog.dirs=/mnt/c/kafka-logs\n</code></pre> </li> <li> <p>If something goes wrong, you'll see familiar MQ reason codes in the error messages to help you diagnose the problems, such as:</p> <pre><code>ERROR MQ error: CompCode 2, Reason 2538 MQRC_HOST_NOT_AVAILABLE\n</code></pre> <p>You can just kill the worker, fix the problem and start it up again.</p> </li> </ul>"},{"location":"kafka-client/#conclusion","title":"Conclusion","text":"<p>Congratulations! You have now tested a simple example of running MQ and Kafka together using the source connector send messages from the direction of z/OS to Kafka. While client mode is a easy way to get started, running the kafka connector in bindings mode is optimal due the improved CPU consumption and latency. Additionally, because the kafka connector is written in java, it is zIIP eligible.</p> <p>Acknowledgements: MQ Development team</p>"},{"location":"logging/","title":"Replaying a persistent message from log","text":""},{"location":"logging/#audience-level","title":"Audience level","text":"<p>Beginner; Some knowledge of MQ or z/OS </p>"},{"location":"logging/#skill-set","title":"Skill set","text":"<p>MQ Administration, z/OS systems programming</p>"},{"location":"logging/#background","title":"Background","text":"<p>Recovery logs are a critical component of resiliency of IBM MQ for z/OS. Administrators can use the CSQ1LOGP and CSQ4LOGS utilities to analyze relevant portions of the MQ log. CSQ1LOGP and CSQ4LOGS are included with the MQ for z/OS product.</p>"},{"location":"logging/#overview-of-exercise","title":"Overview of exercise","text":"<p>This lab is to demonstrate using the provided utilities to replay a persistent message from the queue manager log. It will employ CSQUTIL to create a queue, use OEMPUT to put a single persistent message, use the MQ Explorer to look at the message, OEMPUT to get the message from the queue, CSQ1LOGP to extract the message based on the pageset used, CSQ4LOGS to replay the message, and the same module to do an activity summary. </p> <p>Lab Steps</p> <p>1)   In the TEAMXX.MQPERF.LOG.JCL PDS (where the TEAMXX is your TEAM ID), select the  DEFQLOG member.  This job defines two queues that will be used in the jobs that follow.</p> <p></p> <p>2)  Using a change all command, alter the \u2018++\u2019 variables as listed in the JCL comments:</p> <p>CHANGE ++TEAMXX++ TO YOUR TEAM ID           CHANGE ++LPAR++ TO THE LPAR ON YOUR WORKSHEET  CHANGE ++QMGR++ TO THE QMGR ON YOUR WORKSHEET  CHANGE ++MQHLQ++ TO THE MQ HIGH LEVEL QUALIFIER  CHANGE ++STGCLAS++ TO YOUR TEAM NUMBER  </p> <p>NOTE:  The MQHLQ is MQ910.  The STGCLAS may be different from the pageset ID, which will be used later to isolate the message(s) to extract and replay.  </p> <p>3)  After the changes the statements should looks something like this (TEAM20 used as an example)</p> <p>CHANGE TEAM20 TO YOUR TEAM ID             CHANGE MPX2 TO THE LPAR ON YOUR WORKSHEET  CHANGE QML2 TO THE QMGR ON YOUR WORKSHEET  CHANGE MQ910 TO THE MQ HIGH LEVEL QUALIFIER  CHANGE 20 TO YOUR TEAM NUMBER               </p> <p>4)  Save and submit the job.  5)  Navigate to SDSF.ST to review the results. \u2003 6)  Select the job, using the question mark to display the list of files:</p> <p></p> <p>7)  Select it as shown. The output should indicate success \u2013 this is important to check, as there are times when the job will receive a zero return code, but the queue has not actually been created.  The output should look like this:</p> <p></p> <p>8)  Return to the JCL PDS and select the LOGPUT member. 9)  Using a change all command, alter the \u2018++\u2019 variables as listed in the JCL comments:</p> <p>CHANGE ++TEAMXX++ TO YOUR TEAM ID           CHANGE ++LPAR++ TO THE LPAR ON YOUR WORKSHEET  CHANGE ++QMGR++ TO THE QMGR ON YOUR WORKSHEET  CHANGE ++MQHLQ++ TO THE MQ HIGH LEVEL QUALIFIER</p> <p>10) After the changes the statements should looks something like this (TEAM20 used as an example)</p> <p>CHANGE TEAM20C TO YOUR TEAM ID             CHANGE MPX2 TO THE LPAR ON YOUR WORKSHEET  CHANGE QML2 TO THE QMGR ON YOUR WORKSHEET  CHANGE MQ910 TO THE MQ HIGH LEVEL QUALIFIER  11) Save and submit the JCL. 12) Navigating to the output, using the SDSF.ST option, the SYSPRINT output should look something like the example shown here:  </p> <p></p> <p>13) Open the MQ Explorer, if the you do not see the queue managers QML1 or QML2 please go to the Appendix to see how to add them to the list of available queue managers.  14) Browse the messages on the queue.  To browse the messages, right click on the queue name and select Browse Messages.  \u2003 15) Right click on the message and select \u2018Properties\u2019 .  This should open the following panel:</p> <p> \u2003 16) Select the \u2018Identifiers\u2019 tab and look at the message ID</p> <p></p> <p>17) Using the scroll, move to the right displaying the remainder of the message identifier bytes. </p> <p></p> <p>18) Close the panel. </p> <p>19) Returning to the JCL PDS, select the LOGGET member and make changes to the \u2018++\u2019 variables like the changes made to the LOGPUT member.  </p> <p>20) Save and submit the LOGGET job.   Note that this task will take slightly more than a minute to complete, as it defaults to a get wait of 60 seconds.  In addition it will return a 2033 reason code. \u2003 21) Navigating to the output, using the SDSF.ST option, the SYSPRINT output should look something like the example shown here:  </p> <p></p> <p>22) Note that the total messages retrieved is 1.  Returning to the MQ Explorer, the current queue depth should now be zero.  </p> <p>23) At this point, you have now successfully put and gotten a persistent message. </p> <p>24) Returning to the JCL PDS, select the LOGEXTR1 member.  This is an execution of the  CSQ1LOGP task.  Make the global changes to the \u2018++\u2019 variables, with the exception of the PAGESET and active log variables.</p> <p>CHANGE ++PAGESET++ TO THE PAGESET NUMBER USED FOR THE QUEUE CHANGE ++LOGNAME++ TO THE ACTIVE LOG WHERE THE MESSAGE WAS PUT</p> <p>25) To get the pageset number: a.  From the MQ Explorer, display the storage classes.  It should look something like this:</p> <p></p> <p>b.  Match the name of the storage class used to the pageset ID.  In the example for the lab document, the pageset associated with STGCLS09 is \u201851\u2019. c.  Change the all instances of the  ++PAGESET++ variable to the pageset from this list. </p> <p>26) To get the name of the active log data set, navigate to the SDSF.DA panel and alter the prefix to display the queue manager and channel initiator.  The command to do that is PREFIX QML* and the output should look something like this (example is for the MPX2 LPAR):</p> <p></p> <p>27) Expand the MSTR output for your primary queue manager and select the JESMSGLG output.  The results should look something like what is shown: </p> <p> </p> <p>28) Navigate to the bottom of the output using the \u2018BOT\u2019 command. \u2003 29) Enter the command to display the active log, replacing the \u2018+cpf\u2019 with the queue manager name:</p> <p>+cpf DISPLAY LOG</p> <p>30) At the end of the Display log report, the current active log is given.  In the case of QML1 at the time this was written, this looks as follows:</p> <p></p> <p>31) The last node of the current log name is used to replace the \u2018++LOGNAME++\u2019 variable.  In this case the value is DS001.  </p> <p>32) Change all instances of the ++LOGNAME++ to the value above.  Save and submit the LOGEXTR1 job.  This will extract all the updates made to the pageset.  Note that in a normal production environment this could include many messages for many queues.  The documentation for this may be found here:</p> <p>https://www.ibm.com/support/knowledgecenter/en/SSFKSJ_9.1.0/com.ibm.mq.ref.adm.doc/q088970_.htm </p> <p>33) The start of the output from this job should look as follows:</p> <p></p> <p>NOTE:  The pageset in the \u2018SEARCH CRITERIA\u2019 section is the hex value for the pageset.  </p> <p>34) Scrolling thru the output, you should be able to see the message much like what is shown here:</p> <p></p> <p>35) Return to the JCL PDS and select the LOGJ member.  This executes the sample program CSQ4LOGS to replay the message(s) from the file created by the log extract process.  </p> <p>36) Alter the \u2018++\u2019 variables as done for the previous jobs.  Save and submit the job.  </p> <p>37) The output, in SYSPRINT, gives a description of the actions taken.  In this case, the start should look something like this:</p> <p></p> <p>38) In addition, the queue depth should be back to 1 and browsing the queue should show the restored message.  </p> <p>39) Congratulations!  You have successfully restored a persistent message to a queue! </p> <p>Appendix \u2013 Adding Queue Managers to the MQ Explorer</p> <p>1)  Right click on the \u2018Queue Managers\u2019 folder and select \u2018Add Remote Queue Manager\u2019 </p> <p> </p> <p>2)  Enter QML1 (we will add both queue managers used) and select \u2018Connect directly\u2019. Then click on the \u2018Next\u2019 button (not shown, but it\u2019s on the bottom of the panel). </p> <p> \u2003 3)  Enter \u2018mpx1\u2019 for the Host name or IP address and 1417 as the port number.  Then click on the \u2018Finish\u2019 button. </p> <p></p> <p>4)  Repeat the steps for QML2, using mpx2 as the host name and 1418 as the port. \u2003 5)  The Queue Manager list should now include both the z/OS queue managers used for this lab.</p> <p></p>"},{"location":"mp1b/","title":"Looking at SMF data for problem determination","text":""},{"location":"mp1b/#audience-level","title":"Audience level","text":"<p>Some knowledge of MQ or z/OS </p>"},{"location":"mp1b/#skillset","title":"Skillset","text":"<p>MQ Administration, z/OS systems programming</p>"},{"location":"mp1b/#background","title":"Background","text":"<p>MP1B is a utility provided by IBM to analyze your IBM MQ environment\u2019s performance. MP1B shows you your SMF performance data and allows you to roll it off platform to CSV files for further analysis.</p> <p>MP1B is installable at Link</p> <p>Out of the box, it contains:</p> <p>MQCMD \u2013 a program to display queue statistics and channel status over time</p> <p>MQSMF \u2013 a program for interpreting your own accounting and statistics data</p> <p>OEMPUT - a program to put/get messages in high quantities, useful for testing throughput</p>"},{"location":"mp1b/#overview-of-exercise","title":"Overview of exercise","text":"<p>I.  Set up the local queue MP1B.TESTER</p> <p>II. Make sure settings are in place to record SMF data </p> <p>III.    Run JCL to record our SMF data </p> <p>IV. Navigate the SMF data output to find performance problems in our queue</p> <p>V.  Interpret the performance problem</p> <p>Video tutorial of the following exercise: Link</p>"},{"location":"mp1b/#exercise","title":"Exercise","text":"<ol> <li> <p>MP1B has been installed on this environment, and you can find it by searching for the directory ZQS1.MP1B.JCL in the =3.4 data set search bar.</p> <p></p> </li> <li> <p>Now, outside of z/OS, open up MQ Explorer on your Windows Desktop. The icon should look like this:</p> <p></p> </li> <li> <p>Once you\u2019ve opened MQ Explorer, you should see a left-hand menu bar like below. Right click on the ZQS1 queue manager and hit \u2018Connect\u2019.</p> <p></p> </li> <li> <p>By clicking on the arrow to the left of ZQS1, a dropdown list of MQ objects will appear. Right click on the \u2018Queues\u2019 folder and construct a new local queue called MP1B.TESTER.</p> <p></p> </li> <li> <p>Create a queue on your queue manager using MQ Explorer. The queue should have the following properties: </p> <p></p> </li> </ol> <p>Why make the queue shareable? Great question! Shareable queues tend to come in handy in a test environment, so that developers can browse the queues.</p> <ol> <li> <p>Now that we have our queue defined, head back to z/OS. </p> </li> <li> <p>Now, we will enter a series of MVS commands to adjust the settings of the queue manager to prepare it for the collection of SMF data. To do this, navigate to the ISPF main menu</p> </li> <li> <p>Once in the ISPF main menu, enter \u2018d\u2019 in the command line and hit enter</p> </li> <li> <p>Once in SDSF, place a / in the command input line and hit enter</p> </li> <li> <p>A MVS command prompt like this should pop up:</p> <p></p> </li> <li> <p>Enter the following commands here, one at a time. Each command will take you out of the System Command Extension window, so you will have to use the / command to return to the correct window for executing commands.</p> <pre><code>ZQS1 SET SYSTEM STATIME(1.00)\n</code></pre> <p>To change the statistics time interval to 1 minute</p> <pre><code>ZQS1 SET SYSTEM ACCTIME(-1)\n</code></pre> <p>To change the accounting time interval to match the statistics time interval</p> <pre><code>ZQS1 SET SYSTEM LOGLOAD(200)\n</code></pre> <p>To change the log load attribute to the minimum.</p> <p>We want to modify our queue manager\u2019s log load attribute to be super low in order to manufacture a lot of checkpointing so we see something interesting in the SMF records for the purpose of the lab</p> <pre><code>DISPLAY SMF\n</code></pre> <p>This tells us where our SMF data will be stored</p> <pre><code>ZQS1 ALTER QMGR STATCHL(MEDIUM)\n</code></pre> <p>This tells z/OS we want to enable channel statistics to be collected at a moderate ratio of data collection</p> <pre><code>ZQS1 ALTER QMGR MONQ(MEDIUM)\n</code></pre> <p>This tells z/OS to turn on monitoring for the queue manager\u2019s queues at a moderate ratio of data collection</p> <pre><code>ZQS1 ALTER QMGR MONCHL(MEDIUM)\n</code></pre> <p>This tells z/OS to turn on monitoring for the queue manager\u2019s channels at a moderate ratio of data collection</p> <pre><code>ZQS1 START TRACE(STAT) CLASS(1,2,4,5)\n\nZQS1 START TRACE(ACCTG) CLASS(3,4)\n</code></pre> </li> <li> <p>Now all the settings should be in place for our queue manager. Head back to ZQS1.MP1B.JCL using 3.4 from the main ISPF menu. </p> </li> <li> <p>We will use OEMPUT to load messages into MP1B.TESTER. In the directory ZQS1.MP1B.JCL, place an \u2018e\u2019 to the left of the OEMPUT member. </p> <p></p> </li> <li> <p>Make sure that your queue manager and queue names are correct in lines 46 and 47.</p> </li> <li> <p>Once in OEMPUT, type \u2018submit\u2019 on the command line and hit enter to load persistent messages into the queue manager.</p> <p>I won\u2019t summarize the whole JCL, but pay attention to this particular line:  </p> <p><code>PARM=('-M&amp;QM -tm3 -Q&amp;Q -crlf -fileDD:MSGIN -P')</code></p> <p>Lets break it down:</p> Parameter Meaning '-M&amp;QM Queue manager name -tm3 Send messages for 3 minutes -Q&amp;Q The queue name -crlf Each line in the input message file is used in sequence as message data -fileDD:MSGIN Use the MSGIN file as input -P Use persistent messages </li> <li> <p>If you look at your MQ Explorer, you should now see that your queue is populated with lots of messages! </p> <p></p> </li> <li> <p>Back in ZQS1.MP1B.JCL, navigate to the SMFDUMP member. Once inside, enter \u2018submit\u2019 on the command line to execute SMFDUMP JCL. The SMFDUMP JCL starts with deleting old tasks, then outputs it in a specified location, in our case, ZQS1.QUEUE.MQSMF.SHRSTRM2.</p> <p></p> </li> <li> <p>You can check that the SMFDUMP is processing by navigating to your job using SDSF. Access SDSF using =D from the ISPF menu.</p> </li> <li>Once in SDSF, select ST from the menu and hit \u2018enter\u2019</li> <li>Type in \u2018prefix ZQS1*\u2019. This will show you a list of all jobs submitted that start with ZQS1. Remember, we define our job names at the top left of each JCL file.  </li> <li>Here, you put a \u2018?\u2019 mark besides the jobname. Hit enter, then a screen with a SYSPRINT menu option should pop up. Next to SYSPRINT, put a \u2018s\u2019 and hit enter.</li> <li> <p>Enter \u2018bottom\u2019 on the command line and you should see a screen like below, indicating that records are being written. You can also confirm this by looking in the output for the SUMMARY ACTIVITY REPORT.</p> <p></p> </li> <li> <p>After submitting, you will have to submit another job MQSMFP in ZQS1.MP1B.JCL. This job will give us some formatted information about the SMF data. Make one change before submitting: ensure that the julian date is correct. For labs taking place on 2/24/2025, the julian date is 25055.</p> </li> <li> <p>Type \u2018submit\u2019 and hit enter.</p> <p></p> </li> <li> <p>Now, navigate to the SDSF output for the submitted job. We will be able to see the SMF output in useful categories that can also be exported as CSV files.</p> <p></p> </li> <li> <p>Navigate to the LOG statistics by putting a \u2018s\u2019 next to it and hitting enter. Scroll down until you see a screen similar to the one below. </p> </li> <li> <p>Here you can see LLCheckpoints has a value of 1564. Within our interval, we would expect this value to be 0\u2019s or single-digits. 1564 is way too high. This indicates we should adjust our LOGLOAD attribute to have it write more log records between checkpoints.</p> <p></p> </li> </ol>"},{"location":"mp1b/#summary","title":"Summary","text":"<p>The LOGLOAD parameter specifies the number of log records that are written between checkpoints. In the figure above, you can see the LOGLOAD indicated by the blue brackets. For the above image\u2019s example, the LOGLOAD looks to be 6 here (6 would be impossibly small in a real environment). We set our queue manager\u2019s LOGLOAD attribute to the lowest possible value of 200 then flood our environment with messages. We saw see this cause high checkpointing in our recorded SMF window, resulting in unnecessary consumption of processor time and additional I/O.</p>"},{"location":"new-queue-manager/","title":"Customizing a new queue manager on IBM MQ for z/OS","text":""},{"location":"new-queue-manager/#audience-level","title":"Audience level","text":"<p>Some knowledge of MQ or z/OS </p>"},{"location":"new-queue-manager/#skillset","title":"Skillset","text":"<p>z/OS Systems Programming, MQ Administration</p>"},{"location":"new-queue-manager/#background","title":"Background","text":"<p>Every time a new release of IBM MQ for z/OS is installed, you have the opportunity to create or migrate a new queue manager with the latest capabilities of the IBM MQ release. We will go through the process of creating a new queue manager with IBM MQ for z/OS 9.4.1. IBM MQ for z/OS has been installed on the environment before the lab, so that will installation process will not be in scope of today\u2019s lab.  To start a new queue manager, JCL procedures need to be copied to a system JCL procedure library and the new queue manager subsystem needs to be defined to MVS. </p>"},{"location":"new-queue-manager/#overview-of-exercise","title":"Overview of exercise","text":"<p>What needs to be done here:  I.  Copy and tailor the sample JCL. Each of these members comes pre-canned in the IBM MQ installation. What your task is as an administrator is to customize these for your specific need. II. Run jobs to create the bootstrap data sets and log data sets III.    Add MSTR and CHIN to SYS1.PROCLIB, the started task library IV. Dynamically add MQ subsystem to MVS V.  Define subsystem security VI. Start the queue manager and channel initiator</p>"},{"location":"new-queue-manager/#lab-begin","title":"Lab begin","text":""},{"location":"new-queue-manager/#i-copy-and-tailor-the-sample-jcl","title":"I. Copy and tailor the sample JCL","text":"<ol> <li> <p>We will start with copying the members from the IBM MQ code installation. All the IBM MQ installation will be under the high level qualifier MQ941CD. We are only interested in the sample code here, under SCSQPROC. (*) specifies we want all the members in the SCSQPROC dataset. Go to option =3.3</p> </li> <li> <p>We are making a new queue manager called ZQS3, so we want the new dataset to be referenceable by the high-level qualifier ZQS3. Hit enter.</p> </li> <li> <p>Type a \u20181\u2019 next to option 1. We want the new dataset to have the attribute of MQ941CD.SCSQPROC. Hit enter. </p> </li> <li> <p>In the top right corner, you should see z/OS confirm that 113 members have been copied to the new dataset you created ZQS3.SCSQPROC. Great! We just need one more thing before we can customize. We are going to steal it from already-existing queue manager ZQS2 in this instance. </p> </li> <li> <p>QMEDIT is a REXX EXEC that will help us customize our sample code efficiently. We want to name it QMEDIT under our ZQS3 dataset as well. Hit enter and you should see in the top right corner, \u2018QMEDIT copied\u2019.</p> </li> <li> <p>Now, from the ISPF main screen, if we enter \u2018=3.4\u2019 into the command line and hit enter. We should be able to navigate to our newly created dataset. Copy the below screen and hit enter.</p> </li> <li> <p>Hit enter</p> </li> <li> <p>Browse the dataset by entering a \u2018b\u2019 to the left of the dataset name and hit enter. </p> </li> <li> <p>We will need to customize the following members of the dataset to effectively create a new queue manager:</p> JCL job Description CSQ4BSDS Creates bootstrap data sets CSQ4CHIN Sample Channel Initiator JCL procedure CSQ4MSTR Sample Queue Manager JCL procedure CSQ4INPX Sample commands related to the channel initiator CSQ4INYG Commands to define objects that are normally required CSQ4PAGE Creates page sets for QM storage CSQ4ZPRM Creates the queue manager initiation attributes </li> <li> <p>Instead of manually customizing each of these, we will use our QMEDIT to help us customize quickly. Use \u2018F8\u2019 to navigate down to QMEDIT from the list of members in ZQS3.SCSQPROC. Place a \u2018e\u2019 to the left of QMEDIT and hit enter.</p> </li> <li> <p>Once inside QMEDIT, look through the code and see what the code is customizing. Since this was last used for ZQS2, you will see ZQS2 mentioned a lot. We need to change that. a.  Enter the command \u2018C \u2018ZQS2\u2019 \u2018ZQS3\u2019 ALL\u2019 on the command line and hit enter.  b.  Enter the command \u2018C \u2018MQ933CD\u2019 \u2018MQ941CD\u2019 ALL on the command line and hit enter. c.  Enter the command \u2018C \u20181424\u2019 \u20181425\u2019 ALL\u2019 on the command line and hit enter so there isn\u2019t a port number overlap with ZQS2.</p> </li> <li> <p>By entering the above commands, we\u2019re customizing the REXX exec to the data sets of this particular z/OS environment</p> </li> <li> <p>Now, our REXX exec should be ready to use because it has the correct version of MQ specified, our desired queue manager name, our desired storage areas, and English. Each of those things need to be specified from the original sample code.</p> </li> <li> <p>We need to activate the QMEDIT code to be able to go through our relevant members and customize them quickly. Use F3, return to the ISPF main menu and enter option 6. Enter this command:</p> </li> <li> <p>Hit enter. With ALTLIB, a user or ISPF application can easily activate and deactivate CLIST and REXX exec libraries as the need arises. We are activating the REXX exec library of QMEDIT here to enable customization.</p> </li> <li>From the ISPF main menu, navigate back to the ZQS3.SCSQPROC members via option 3.4.</li> <li>Starting with CSQ4BSDS, we will customize: a.  CSQ4BSDS b.  CSQ4CHIN c.  CSQ4MSTR d.  CSQ4INPX e.  CSQ4INYG f.  CSQ4PAGE g.  CSQ4ZPRM</li> <li>Enter an \u2018e\u2019 next to CSQ4BSDS and hit enter from the member list. Once inside CSQ4BSDS, enter QMEDIT on the command input line and hit enter.</li> </ol> <p>NOTE: You must execute QMEDIT in the same session as you executed the ALTLIB command from. Otherwise, you will get the error message \u2018QMEDIT not found\u2019.</p> <ol> <li>You should notice the changes by looking through CSQ4BSDS, using F7 and F8 to navigate up and down the JCL code. Enter F3 to return to the member list and save your changes to CSQ4BSDS.</li> <li>Now, navigate back to the ZQS3.SCSQPROC list. Repeat this process for: a.  CSQ4CHIN b.  CSQ4MSTR c.  CSQ4INPX d.  CSQ4INYG e.  CSQ4PAGE f.  CSQ4ZPRM</li> <li>We are going to make an additional customization on CSQ4PAGE. Navigate to the member using \u2018e\u2019 to the left of the member. Once inside, enter the following commands on the command line at the bottom and hit enter.  a.  c 'VOL=SER' 'STORCLAS' all b.  c 'VOLUMES' 'STORCLAS' all</li> <li>We\u2019re using system managed storage devices now instead of volumes, as is the standard on z/OS now</li> <li>F3 to save the changes. We have to customize the storage here to be appropriate for this z/OS image.</li> <li>Next, we\u2019re going to modify CSQ4ZPRM. Use QMEDIT like normal, then enter the command: c \u2018++HLQ.USERAUTH++\u2019 \u2018ZQS1.USERAUTH\u2019 ALL</li> <li> <p>Last, modify CSQ4CHIN using \u2018e\u2019. Use QMEDIT like normal, then we are going to make one more additional customization on CSQ4CHIN. Once inside CSQ4CHIN, enter the command \u2018f user exit library\u2019. This will find the appropriate JCL.</p> </li> <li> <p>We want to comment the lines 94 and 119 out. Insert a \u201c*\u201d in the front of the line so that the asterisk lines up with the asterisk on the line below. It should look like this: </p> </li> <li> <p>F3 out of CSQ4CHIN to save your changes and return to the member list. </p> </li> <li>You can enter the command \u2018SORT CHANGED\u2019 from the member list panel to ensure you customized all the essential members</li> </ol>"},{"location":"new-queue-manager/#ii-run-jobs-to-create-the-bootstrap-data-sets-and-log-data-sets","title":"II. Run jobs to create the bootstrap data sets and log data sets","text":"<ol> <li>Now, your customization is complete. Enter \u2018e\u2019 next to CSQ4BSDS and input \u2018SUBMIT\u2019 on the command line. This will create our bootstrap data sets for the new queue manager. </li> <li> <p>Repeat this for CSQ4PAGE to set up the page sets for the new queue manager. </p> </li> <li> <p>Last, submit CSQ4ZPRM using the same process as CSQ4BSDS and CSQ4PAGE</p> </li> <li> <p>When you return to the main ISPF menu, use option 3.4 to navigate to all the ZQS3 libraries</p> </li> <li> <p>Once you hit enter, you should now see boot strap data set and page set files set up along with our original ZQS3.SCSQPROC data set. If you do not see the new data sets, something has failed in your JCL and you will need to debug. We recommend comparing the BSDS and PAGE JCL to the JCL of a working queue manager, for example, ZQS1. III. Add MSTR and CHIN to SYS1.PROCLIB, the started task library</p> </li> <li> <p>Now, we have to edit SYS1.PROCLIB. Navigate to SYS1.PROCLIB using 3.4 on the ISPF menu. SYS1.PROCLIB needs to contain two members for ZQS3, ZQS3MSTR and ZQS3CHIN. We can add these two members by copying our CSQ4MSTR and CSQ4CHIN and renaming them.</p> </li> <li> <p>From the ISPF main menu, go to 3.3. Here, specify that you would like to copy from \u2018ZQS3.SCSQPROC(CSQ4MSTR)\u2019 to \u2018SYS1.PROCLIB(ZQS3MSTR)\u2019. This will create a copy of your edited member for SYS1.PROCLIB and it will also rename the member to ZQS3MSTR.</p> </li> <li> <p>Repeat this copying process for CSQ4CHIN i.e. \u2018ZQS3.SCSQPROC(CSQ4CHIN)\u2019 to \u2018SYS1.PROCLIB(ZQS3CHIN)\u2019.</p> </li> <li>Now, if you navigate to SYS1.PROCLIB using option 3.4, you should see the members ZQS3MSTR and ZQS3CHIN listed as members.</li> </ol>"},{"location":"new-queue-manager/#iv-dynamically-add-mq-subsystem-to-mvs","title":"IV. Dynamically add MQ subsystem to MVS","text":"<ol> <li>Now, all the setup is complete, so we just have to start up the queue manager!</li> <li>The next few commands will all be entered in the MVS command area. Navigate there by entering \u2018D\u2019 in the ISPF menu command line to navigate to SDSF. Once in SDSF, enter a slash in your command input and hit enter like so:</li> <li>Execute command to dynamically define MQ subsystem:  a.  SETSSI ADD,S=ZQS3,I=CSQ3INI,P='CSQ3EPX,ZQS3,S'</li> </ol> <p>NOTE! None of these dynamic commands will last through an IPL of the system. To make these changes concrete, you will need to modify the LPALST##, IEFSSN## and PROG## members of the LPAR\u2019s SYS1.PARMLIB data set.</p>"},{"location":"new-queue-manager/#v-define-subsystem-security","title":"V. Define subsystem security","text":"<ol> <li>F3 back to the main menu, out of SDSF, enter option 6 from the main menu. Here, you will find a TSO command input window: a.  Turn off security by entering this command: </li> </ol> <p>NOTE! Never turn off security outside of workshop lab environments.</p> <ol> <li>You will see an output like this, indicating this has already been done for you, but this enables you to see how we did it. Obviously, you will not be disabling security in any of your environments, just in our test environment.  </li> </ol>"},{"location":"new-queue-manager/#vi-starting-your-queue-manager-and-channel-initiator","title":"VI. Starting your queue manager and channel initiator","text":"<ol> <li>Return to the SDSF command window and input the commands into the MVS command line:</li> </ol> <p>a.  Start up our queue manager ZQS3 with the command: ZQS3 START QMGR b.  Start up the channel initiator with the command: ZQS3 START CHINIT c.  Start up the listener with the command: ZQS3 start listener TRPTYPE(TCP) Port(1425) 44. To verify that your queue manager has been set up, you can navigate to MQ Explorer and test the connection. You will use the port number you specified in the REXX exec. 45. Congrats! You have created a queue manager from scratch! Lab COMPLETE!</p>"},{"location":"new-queue-manager/#appendix","title":"Appendix:","text":"<p>\u2022 REXX EXEC is not included with the base product \u2013 describe ++ variables </p> <p>\u2022 Make an error when executing your SETSSI command? Use SETSSI DELETE,S=ZQS3,FORCE to roll back your command.</p> <p>\u2022 Check APF authorized libraries by entering the command /DISPLAY PROG,APF from the SDSF command input then going to the log. </p> <pre><code>APF authorized libraries must be:\n    o   MQ941CD.SCSQANLE\n    o   MQ941CD.SCSQAUTH\n    o   MQ941CD.SCSQMVR1\n    \u2022   You may see several LPALST## PROG##, and IEFSSN## members. You want to use the ones specified in the SYS1.PARMLIB(IEASYS##). You can find the IEASYS## member by entering the command /D IPLINFO from the SDSF command input. It will show a screen like this:\n</code></pre> <p>\u2022 Looking to permanently make updates to your LPALST## member?</p> <pre><code>o   Add code like this:\n\n\u2022   Looking to permanently make updates to your IEFSSN## member?\n\na.  Add code like this:\n\n\u2022   Looking to permanently make updates to your PROG## member?\n\no   Add code like this:\n\n\u2022 Need to dynamically APF authorize your MQ load libraries?\n    o   SETPROG APF,ADD,DSNAME=MQ941CD.SCSQANLE ,SMS   \n    o   SETPROG APF,ADD,DSNAME=MQ941CD.SCSQSNLE ,SMS\n\n\u2022 Need to dynamically add some modules to the LPA (link pack area) of z/OS?\n    o   SETPROG LPA,ADD,MODNAME=(CSQ3EPX,CSQ3INI),DSNAME=MQ941CD.SCSQLINK\n    o   SETPROG LPA,ADD,MODNAME=(CSQ3ECMX),DSNAME=MQ941CD.SCSQSNLE\n</code></pre>"},{"location":"qm_upgrade/","title":"Customizing a new queue manager on IBM MQ for z/OS","text":""},{"location":"qm_upgrade/#audience-level","title":"Audience level","text":"<p>Some knowledge of MQ or z/OS </p>"},{"location":"qm_upgrade/#skillset","title":"Skillset","text":"<p>z/OS Systems Programming, MQ Administration</p>"},{"location":"qm_upgrade/#background","title":"Background","text":"<p>This lab walks users through how to upgrade queue managers on z/OS. This lab assumes the SMP/E work has already been done to install the product. In this lab, we will use MQ v.9.4.2 as an example. As such, our high level qualifier is MQ942CD.</p>"},{"location":"qm_upgrade/#overview-of-exercise","title":"Overview of exercise","text":"<p>What needs to be done here:  I. Stop queue manager II. OPTIONAL: Re-bind queue sharing group  III. Adjust MSTR and CHIN started tasks III. Update early code IV. Restart queue manager</p>"},{"location":"qm_upgrade/#lab-begin","title":"Lab begin","text":""},{"location":"qm_upgrade/#i-stop-queue-manager","title":"I. Stop queue manager","text":"<p>1. From the ISPF main menu, type 'SDSF' and press Enter. System Display and Search Facility (SDSF) is a utility that allows you to monitor, control, and view the output of jobs in the system.</p> <p>2. On the SDSF menu, type '/' and press Enter to access the MVS command line via the System Command Extension.</p> <p>3. On the command line, type 'ZQS1 STOP CHINIT'</p> <p>4. Next, type 'ZQS1 STOP QMGR'</p>"},{"location":"qm_upgrade/#ii-optional-re-bind-queue-sharing-group","title":"II. OPTIONAL: Re-bind queue sharing group","text":""},{"location":"queue-statistics/","title":"Evaluating queue performance with queue statistics","text":""},{"location":"queue-statistics/#audience-level","title":"Audience level","text":"<p>Some knowledge of MQ or z/OS </p>"},{"location":"queue-statistics/#skillset","title":"Skillset","text":"<p>MQ Administration, z/OS systems programming</p>"},{"location":"queue-statistics/#background","title":"Background","text":"<p>Queue statistics was introduced into the IBM MQ for z/OS product in continuous delivery version 9.3.3. This lab is a modification of the MP1B performance lab to demonstrate how to access per-queue statistics data. Queue statistics fields are well-documented at the following link: Link</p> <p>For this lab, we will be using MP1B to produce a performance report. MP1B is a utility provided by IBM to analyze your IBM MQ environment\u2019s performance. MP1B shows you your SMF performance data and allows you to roll it off platform to CSV files for further analysis.</p> <p>MP1B is installable at Link</p> <p>Out of the box, it contains:</p> <p>MQCMD \u2013 a program to display queue statistics and channel status over time</p> <p>MQSMF \u2013 a program for interpreting your own statistics data, including queue statistics</p> <p>OEMPUT - a program to put/get messages in high quantities, useful for testing throughput</p>"},{"location":"queue-statistics/#overview-of-exercise","title":"Overview of exercise","text":"<p>I.  Set up the local queue MP1B.TESTER</p> <p>II. Make sure settings are in place to record SMF data </p> <p>III.    Run JCL to record our SMF data </p> <p>IV. Navigate the SMF data output to find performance problems </p> <p>V.  Interpret the performance problem</p>"},{"location":"queue-statistics/#exercise","title":"Exercise","text":""},{"location":"queue-statistics/#i-set-up-the-local-queue-mp1btester","title":"I. Set up the local queue MP1B.TESTER","text":"<ol> <li> <p>MP1B has been installed on this environment, and you can find it by searching for the directory ZQS1.MP1B.JCL in the =3.4 data set search bar.</p> <p></p> </li> <li> <p>Now, outside of z/OS, open up MQ Explorer on your Windows Desktop. The icon should look like this:</p> <p></p> </li> <li> <p>Once you\u2019ve opened MQ Explorer, you should see a left-hand menu bar like below. Right click on the ZQS1 queue manager and hit \u2018Connect\u2019.</p> <p></p> </li> <li> <p>By clicking on the arrow to the left of ZQS1, a dropdown list of MQ objects will appear. Right click on the \u2018Queues\u2019 folder and construct a new local queue called MP1B.TESTER.</p> <p></p> </li> <li> <p>Create a queue on your queue manager using MQ Explorer. The queue should have the following properties: </p> <p></p> </li> </ol> <p>Why make the queue shareable? Great question! Shareable queues tend to come in handy in a test environment, so that developers can browse the queues.</p> <ol> <li>Now that we have our queue defined, head back to z/OS. </li> </ol>"},{"location":"queue-statistics/#ii-make-sure-settings-are-in-place-to-record-smf-data","title":"II.    Make sure settings are in place to record SMF data","text":"<ol> <li> <p>Now, we will enter a series of MVS commands to adjust the settings of the queue manager to prepare it for the collection of SMF data. To do this, navigate to the ISPF main menu</p> </li> <li> <p>Once in the ISPF main menu, enter \u2018d\u2019 in the command line and hit enter</p> </li> <li> <p>Once in SDSF, place a / in the command input line and hit enter</p> </li> <li> <p>A MVS command prompt like this should pop up:</p> <p></p> </li> <li> <p>Enter the following commands here, one at a time. Each command will take you out of the System Command Extension window, so you will have to use the / command to return to the correct window for executing commands.</p> <pre><code>ZQS1 SET SYSTEM STATIME(1.00)\n</code></pre> <p>To change the statistics time interval to 1 minute</p> <p>We want to modify our queue manager\u2019s log load attribute to be super low in order to manufacture a lot of checkpointing so we see something interesting in the SMF records for the purpose of the lab</p> <pre><code>DISPLAY SMF\n</code></pre> <p>This tells us where our SMF data will be stored</p> <pre><code>ZQS1 ALTER QMGR STATCHL(MEDIUM)\n</code></pre> <p>This tells z/OS we want to enable channel statistics to be collected at a moderate ratio of data collection</p> <pre><code>ZQS1 ALTER QMGR MONQ(MEDIUM)\n</code></pre> <p>This tells z/OS to turn on monitoring for the queue manager\u2019s queues at a moderate ratio of data collection</p> <pre><code>ZQS1 ALTER QMGR MONCHL(MEDIUM)\n</code></pre> <p>This tells z/OS to turn on monitoring for the queue manager\u2019s channels at a moderate ratio of data collection</p> <pre><code>ZQS1 START TRACE(STAT) CLASS(1,2,4,5)\n</code></pre> </li> <li> <p>Now all the settings should be in place for our queue manager. Head back to ZQS1.MP1B.JCL using 3.4 from the main ISPF menu. </p> </li> </ol>"},{"location":"queue-statistics/#iii-run-jcl-to-record-our-smf-data","title":"III.    Run JCL to record our SMF data","text":"<ol> <li> <p>We will use OEMPUT to load messages into MP1B.TESTER. In the directory ZQS1.MP1B.JCL, place an \u2018e\u2019 to the left of the OEMPUT member. </p> <pre><code>    //************************************************\n//*                                               \n//  SET QM=ZQS1                                   \n//  SET Q=TEAM1.STREAM.BASE                       \n//S1   EXEC PGM=OEMPUT,REGION=0M,                 \n//  PARM=('-M&amp;QM -tm1 -Q&amp;Q -fileDD:MSGIN -P  ')   \n//SYSIN  DD *                                     \n/*                                                \n//STEPLIB  DD DISP=SHR,DSN=ZQS1.MP1B.LOAD         \n//         DD DISP=SHR,DSN=MQ940CD.SCSQLOAD       \n//         DD DISP=SHR,DSN=MQ940CD.SCSQAUTH       \n//         DD DISP=SHR,DSN=MQ940CD.SCSQANLE       \n//SYSPRINT DD SYSOUT=*                            \n//MSGIN    DD DISP=SHR,DSN=ZQS1.MQ.JCL(MSGS)      \n//                                                \n</code></pre> </li> <li> <p>Make sure that your queue manager and queue names are correct in lines 46 and 47.</p> </li> <li> <p>Once in OEMPUT, type \u2018submit\u2019 on the command line and hit enter to load persistent messages into the queue manager.</p> <p>I won\u2019t summarize the whole JCL, but pay attention to this particular line:  </p> <p><code>PARM=('-M&amp;QM -tm3 -Q&amp;Q -crlf -fileDD:MSGIN -P')</code></p> <p>Lets break it down:</p> Parameter Meaning '-M&amp;QM Queue manager name -tm3 Send messages for 3 minutes -Q&amp;Q The queue name -crlf Each line in the input message file is used in sequence as message data -fileDD:MSGIN Use the MSGIN file as input -P Use persistent messages </li> <li> <p>If you look at your MQ Explorer, you should now see that your queue is populated with lots of messages! </p> <p></p> </li> <li> <p>Back in ZQS1.MP1B.JCL, navigate to the SMFDUMP member. Once inside, modify the date to be accurate. If you are completing this lab on 2/24/2025 at SHARE, the date will be 2025055. Additionally adjust the START parameter to reflect the appropriate hh:MM. Your JCL should look something like:     <pre><code>//SYSIN  DD *                                          \nLSNAME(IFASMF.DEFAULT,OPTIONS(DUMP))                 \nOUTDD(DUMPOUT,TYPE(115,116),START(1230),END(2200))   \nDATE(2025055,2025055)     \n</code></pre></p> </li> </ol> <p>This is a date in the Julian format.</p> <ol> <li> <p>Enter \u2018submit\u2019 on the command line to execute SMFDUMP JCL. The SMFDUMP JCL starts with deleting old tasks, then outputs it in a specified location, in our case, ZQS1.QUEUE.MQSMF.SHRSTRMx.</p> </li> <li> <p>You can check that the SMFDUMP is processing by navigating to your job using SDSF. Access SDSF using =D from the ISPF menu.</p> </li> <li>Once in SDSF, select ST from the menu and hit \u2018enter\u2019</li> <li>Type in \u2018prefix ZQS1*\u2019. This will show you a list of all jobs submitted that start with ZQS1. Remember, we define our job names at the top left of each JCL file.  </li> <li>Here, you put a \u2018?\u2019 mark besides the jobname. Hit enter, then a screen with a SYSPRINT menu option should pop up. Next to SYSPRINT, put a \u2018s\u2019 and hit enter.</li> <li> <p>Enter \u2018bottom\u2019 on the command line and you should see a screen like below, indicating that records are being written. You can also confirm this by looking in the output for the SUMMARY ACTIVITY REPORT.</p> <p></p> </li> <li> <p>You will have to submit one final job MQSMFP in ZQS1.MP1B.JCL. This job will give us some formatted information about the SMF data. Type \u2018submit\u2019 and hit enter.</p> <pre><code>//****************************************************************\n//*                                                               \n//S1 EXEC PGM=MQSMF,REGION=0M                                     \n//STEPLIB  DD DISP=SHR,DSN=ZQS1.MP1B.LOAD                         \n//SMFIN    DD DISP=SHR,DSN=ZQS1.QUEUE.MQSMF.SHRSTRM6              \n//SYSIN    DD *                                                   \nDETAIL 5                                                         \nSMF_Interval_time 900                                            \n/*                                                                \n//SYSPRINT DD SYSOUT=*,DCB=(LRECL=200)                            \n//SYSOUT   DD SYSOUT=*,DCB=(RECFM=VB,LRECL=200,BLKSIZE=27998)     \n//SYSERR   DD SYSOUT=*                                            \n//ADAP     DD SYSOUT=*                                            \n//ADAPCSV  DD SYSOUT=*                                            \n//BUFF     DD SYSOUT=*,DCB=(LRECL=200)                            \n//BUFFIO   DD SYSOUT=*,DCB=(LRECL=200)                            \n//BUFFCSV  DD SYSOUT=*,DCB=(LRECL=200)                            \n//CF       DD SYSOUT=*                                            \n//CFCSV    DD SYSOUT=*                                            \n//CHINIT   DD SYSOUT=*                                            \n</code></pre> </li> <li> <p>Now, navigate to the SDSF output for the submitted job. We will be able to see the SMF output in useful categories that can also be exported as CSV files.</p> <p></p> </li> <li> <p>Navigate to the QSTATS statistics by putting a \u2018s\u2019 next to it and hitting enter. Once inside QSTATS, on the command line, enter:</p> <p>f MP1B.TESTER</p> </li> <li> <p>Voila, you should now see detailed information about the queue we set up, including the storage. </p> </li> </ol> <p></p>"},{"location":"queue-statistics/#iv-navigate-the-smf-data-output-to-find-performance-problems","title":"IV.    Navigate the SMF data output to find performance problems","text":""},{"location":"queue-statistics/#v-interpret-the-findings","title":"V. Interpret the findings","text":"<p>While we just went through QSTATS output, take some time to explore the other outputs we get with queue statistics. </p> <p>QALL <pre><code>Queue data summarised by queue                                                 \n          0 Open name                                  TEAM1.STREAM.BASE       \n          0 Queue type:  QLocal                        TEAM1.STREAM.BASE       \n          0 Page set ID                        4       TEAM1.STREAM.BASE       \n          0 Buffer pool                        3       TEAM1.STREAM.BASE       \n          0 Put count                      51057       TEAM1.STREAM.BASE       \n          0 Put avg elapsed time            1171 uS    TEAM1.STREAM.BASE       \n          0 Put avg CPU time                  47 uS    TEAM1.STREAM.BASE       \n          0 Put + put1 valid count         51057       TEAM1.STREAM.BASE       \n          0 Inq count                          1       TEAM1.STREAM.BASE       \n          0 Inq avg elapsed time              14 uS    TEAM1.STREAM.BASE       \n          0 Inq avg CPU time                  14 uS    TEAM1.STREAM.BASE       \n          0 Total queue elapsed time    59803352 uS    TEAM1.STREAM.BASE       \n          0 Total queue CPU used         2406244 uS    TEAM1.STREAM.BASE    \n</code></pre> QSTAT</p> <pre><code>Queue statistics                                                                \n\nMQS1,ZQS1,2025/02/24,09:00:06,VRM:940,                                          \n  From 2025/02/24,08:59:05 to 2025/02/24,09:00:05, duration   60 seconds.       \n\nMQS1,ZQS1,2025/02/24,09:00:06,VRM:940,                                          \nQueue Name.................................SYSTEM.PROTECTION.POLICY.QUEUE       \nDisposition................................Private                              \nPageset ID.................................Unallocated                          \nBufferpool ID..............................Unallocated                          \nCurrent Depth..............................0                                    \nOpen Output Count..........................0                                    \nOpen Input Count...........................0                                    \nQTIME Short................................0                                    \nQTIME Long.................................0                                    \nLast Put Time..............................                                     \nLast Get Time..............................                                     \nUncommitted Changes........................No                                   \n</code></pre> <p>QPUTSCSV provides all data relevant to putting messages onto the queue. <pre><code>Queue,Puts,Put1s,TotBytes,MaxMsgSz,MinMsgSz      \nTEAM1.STREAM.BASE,51057,0,40845600,800,800    \n</code></pre></p> <p>QGETSCSV provides all data relevant to getting messages from the queue. QSTATCSV provides all data related to handles, API calls other miscellaneous items.</p> <pre><code>z/OS,QM,Date,Time,Queue,Disp,PSID,BPID,QSG,CF,Dpth,OPPROC,IPPROC,QTIMES,QTIMEL,L\ncLow,IPProcHigh,IPProcLow,MQOPENs,MQCLOSEs,MQINQs,MQSETs,ExpiredMsgs,RecType    \nMQS1,ZQS1,2025/02/24,09:00:06,SYSTEM.PROTECTION.POLICY.QUEUE,Private,Unallocated\n0,Full                                                                          \nMQS1,ZQS1,2025/02/24,09:00:06,QCPY.INPUT,Private,Unallocated,Unallocated,,,0,0,0\nMQS1,ZQS1,2025/02/24,09:00:06,SYSTEM.JMS.ADMIN.QUEUE,Private,Unallocated,Unalloc\nMQS1,ZQS1,2025/02/24,09:00:06,TEAM1.STREAM.BASE,Private,4,3,,,66370,0,0,0,0,2025\n,0,0,0,0,0,Full                                                                 \nMQS1,ZQS1,2025/02/24,09:00:06,CICS01.INITQ,Private,Unallocated,Unallocated,,,0,0\nMQS1,ZQS1,2025/02/24,09:00:06,SYSTEM.JMS.ND.SUBSCRIBER.QUEUE,Private,Unallocated\n0,Full                                                                          \nMQS1,ZQS1,2025/02/24,09:00:06,SYSTEM.JMS.ND.CC.SUBSCRIBER.QUEUE,Private,Unalloca\n,0,0,Full                                                                       \nMQS1,ZQS1,2025/02/24,09:00:06,QCPY.SHARED.CONTROL,Shared,,,QSGA,TEST2       ,0,0\nMQS1,ZQS1,2025/02/24,09:00:06,QCPY.CONTROL,Private,Unallocated,Unallocated,,,0,0\nMQS1,ZQS1,2025/02/24,09:00:06,MSGSELECT.SHAREDQ,Shared,,,QSGA,TEST2       ,1,0,0\nMQS1,ZQS1,2025/02/24,09:00:06,ANSIBLE.DEMO.QUEUE,Private,Unallocated,Unallocated\nMQS1,ZQS1,2025/02/24,09:00:06,SYSTEM.DURABLE.SUBSCRIBER.QUEUE,Private,2,1,,,2,0,\n</code></pre> <p>QSUML data is a summary of the queue usage over time, for local queues.</p> <pre><code>Queue tree                                                                      \nDate,Time,Qmgr,Queue,Count,PS,BP,\"Put MB\",\"Get MB\",!,ValidPut,ValidGet,getpsn,Ma\n2025/02/24,11:00:00, G  ,TEAM1.STREAM.BASE                               ,   2, \n</code></pre> <p>QSUMS data is a summary of the queue usage over time, for shared queues.</p> <pre><code>Queue tree                                                                      \nDate,Time,Qmgr,Queue,Count,Structure,\"Put MB\",\"Get MB\",!,ValidPut,ValidGet,MaxQD\n</code></pre> <p>LAB FINISHED!</p>"},{"location":"securitylab/","title":"Configuring RACF resources for MQ Security","text":""},{"location":"securitylab/#audience-level","title":"Audience level","text":"<p>Some knowledge of MQ or z/OS </p>"},{"location":"securitylab/#skillset","title":"Skillset","text":"<p>MQ Administration, z/OS systems programming</p>"},{"location":"securitylab/#background","title":"Background","text":""},{"location":"securitylab/#exercise-objectives","title":"Exercise Objectives","text":"<p>The objective of this exercise is to gain experience with protecting access to IBM MQ queues, MQ commands and connection to a queue manager using RACF. In this exercise you will enable the RACF protection of these resources and then provide appropriate access to these resources to different sets of users both local and remote.</p> <p>For this exercise, you will be using a data set called ZQS1.SECURITY.JCL. We will be using the following members: -ADDGROUP - Define MQSTC, CICSSTC, MQUSERS and connect users to those groups -MQCMDS -MQCONN -MQQUEUE </p>"},{"location":"securitylab/#important-notes","title":"Important Notes","text":"<p>Before we get started, let's review some RACF terminology you will use in the lab:</p> <p>1) RDEFINE - This command adds a profile for the resource to the RACF database in order to control access to the resource</p> <p>2) PERMIT - This command maintains the lists of users and groups authorized to access a particular resource.</p> <p>Please note: MVS commands are identified by a leading slash (/). This is reminder that these commands need to be entered using SDSF. </p> <p>Please note: Case (upper or lower) is very important when invoking the RACDCERT and keytool commands in this exercise.</p>"},{"location":"securitylab/#lab-begin","title":"Lab Begin","text":""},{"location":"securitylab/#i-enable-security-checking-on-queue-manager-zqs1","title":"I. Enable Security Checking on queue manager ZQS1","text":"<p>External security checking is enabled or disabled for a specific queue manager either by the presence or absence of specific MQADMIN RACF resources during the queue manager initialization. During startup, the queue manager uses its name (e.g. ZQS1) to look for a specific SYSPROG resource. If the resource is defined, then its presence disables the corresponding security checking. </p> <p>For example for queue manager ZQS1, if MQADMIN resource ZQS1.NO.TOPIC.CHECKS is defined then external security checking for topics will be disabled. If MQADMIN resource ZQS1.NO.QUEUE.CHECKS is defined then external security checking for queue access will be  disabled. </p> <p>What we do in this lab is start from the default of security ON, disable security, and then add back customized security settings for our MQ resources.</p> <ol> <li> <p>Log on to TSO/ISPF using your assigned z/OS credentials.</p> </li> <li> <p>From option 6 on the ISPF main menu, use the RACF command <code>LISTGROUP</code> (or LG) to list the users currently connected to the groups described above, e.g. LG SYS1. You will see something like the results below.</p> <pre><code>NO MODEL DATA SET                                                       \nTERMUACC                                                                \nSUBGROUP(S)= DFSGRP   ZFSGRP   ZOSV210  @PL      ABJ      AIO           \n            AOK      AOP      APK      ASM      ATX      AUP           \n            BDT1     B8R      CAZ      CBC      CDS      CEE           \n            CFZ      CKL      CKR      CPAC     CSD      CSF           \n            C4R      DGA      DIT      EEL      ELA      EMS           \n            EOX      EOY      EPH      EQAW     EQQ      EUVF          \n            FFST     FMN      GDDM     GIM      GLD      GSK           \n            HAP      HVT      IBMZ     ICQ      IDI      IGY           \n            IMW      ING      IOA      IOE      IPV      ISF           \n....\nUSER(S)=      ACCESS=      ACCESS COUNT=      UNIVERSAL ACCESS=   \n    IBMUSER       JOIN          000004               READ           \n        CONNECT ATTRIBUTES=NONE                                      \n        REVOKE DATE=NONE                 RESUME DATE=NONE            \n    SYSPROG       JOIN          014895               NONE           \n        CONNECT ATTRIBUTES=NONE                                      \n        REVOKE DATE=NONE                 RESUME DATE=NONE            \n</code></pre> <p>The LISTUSER command can also be useful for investigating the permissions of a particular userid. As an example, LISTUSER USER1</p> </li> </ol> <p>3. To determine what MQADMIN resources are currently defined use the RACF SEARCH command  to display the currently defined MQADMIN resources for ZQS1. </p> <pre><code>SEARCH CLASS(MQADMIN) FILTER(ZQS1.**)\n</code></pre> <p>The results should look like the list below: </p> <pre><code>ZQS1.NO.ALTERNATE.USER.CHECKS \nZQS1.NO.CMD.RESC.CHECKS \nZQS1.NO.CONTEXT.CHECKS \nZQS1.NO.NLIST.CHECKS \nZQS1.NO.PROCESS.CHECKS \nZQS1.NO.SUBSYS.SECURITY \nZQS1.NO.TOPIC.CHECKS \nZQS1.RESLEVEL \n</code></pre> <p>Tech-Tip: All RACF resources associated with a specific queue manager are named with a prefix of the queue manager name. This allows the coexistences of multiples RACF resources for the same base resource name, i.e. ZQS1.SYSTEM.DEFAULT.LOCAL.QUEUE will have different security protection than ZQS2.SYSTEM.DEFAULT.LOCAL.QUEUE.</p> <p>4. The MQADMIN resources in this list disable various MQ external security checks. One of these one in particular disables all external checking regardless of any other MQADMIN resource and that is ZQS1.NO.SUBSYS.SECURITY. If you see  ZQS1.NO.SUBSYS.SECURITY, this indicates that all external security checking is currently disabled. </p> <pre><code>CSQH021I ZQS1 CSQHINIT SUBSYSTEM security switch set \nOFF, profile 'ZQS1.NO.SUBSYS.SECURITY' found\n</code></pre> <p>5. To enable external security checking for the next restart of the queue manager, use the RACF RDELETE command to delete this MQADMIN resource. </p> <pre><code>RDELETE MQADMIN ZQS1.NO.SUBSYS.SECURITY\n</code></pre> <p>6. Refresh the RACF instorage profiles with the RACF SETROPTS command </p> <pre><code>SETROPTS RACLIST(MQADMIN) REFRESH\n</code></pre> <p>7. Shutdown the ZQS1 queue manager with MVS command </p> <pre><code> /ZQS1 STOP QMGR\n</code></pre> <p>Tech-Tip: To disable external security checking use the RDEFINE to command to define this resource.</p> <pre><code>RDEFINE MQADMIN ZQS1.NO.SUBSYS.SECURITY OWNER(SYS1)\n</code></pre> <p>Tech-Tip: You probably will receive message ICH14070I SETROPTS RACLIST REFRESH had no effect on class MQADMIN. Not every RACF configuration requires a refresh of the RACF instorage profiles but it is a good practice to get in the habit of doing a refresh after making changes. This will avoid making a configuration change and not having it made active.</p> <p>CSQH021I ZQS1 CSQHINIT SUBSYSTEM security switch set  OFF, profile 'ZQS1.NO.SUBSYS.SECURITY' found </p> <p>8. Before the queue manager is restarted, some basic MQ RACF resources should be defined. Select member MQCMDS in data set ZQS1.SECURITY.JCL. This JCL defines MQCMDS RACF resources for some of the basic MQ commands and then grants users in group STCMQ and MQADMS access.</p> <ol> <li>Submit MQCMDS for execution and verify that it completes with a condition code of zero. </li> </ol> <p>Tech-Tip: The SEARCH and EXEC commands at the beginning of this job delete all existing MQCMDS profiles for queue manager ZQS1. </p> <pre><code>RDEFINE MQCMDS ZQS1.DEFINE.** OWNER(SYS1) \n\nPERMIT ZQS1.DEFINE.** CLASS(MQCMDS) RESET \n\nPERMIT ZQS1.DEFINE.** CLASS(MQCMDS) ID(MQSTC,MQSYSP) ACC(ALTER) \n\n\nRDEFINE MQCMDS ZQS1.DELETE.** OWNER(SYS1) \n\nPERMIT ZQS1.DELETE.** CLASS(MQCMDS) RESET \n\nPERMIT ZQS1.DELETE.** CLASS(MQCMDS) ID(MQSTC,MQSYSP) ACC(ALTER) \n\n\nRDEFINE MQCMDS ZQS1.DISPLAY.** OWNER(SYS1) \n\nPERMIT ZQS1.DISPLAY.** CLASS(MQCMDS) RESET \n\nPERMIT ZQS1.DISPLAY.** CLASS(MQCMDS) ID(MQSTC,MQUSERS) ACC(READ) \n\n\nRDEFINE MQCMDS ZQS1.REFRESH.** OWNER(SYS1) \n\nPERMIT ZQS1.REFRESH.** CLASS(MQCMDS) RESET \n\nPERMIT ZQS1.REFRESH.** CLASS(MQCMDS) ID(MQSTC,MQSYSP) ACC(ALTER) \n\n\nRDEFINE MQCMDS ZQS1.START.** OWNER(SYS1) \n\nPERMIT ZQS1.START.** CLASS(MQCMDS) RESET \n\nPERMIT ZQS1.START.** CLASS(MQCMDS) ID(MQSTC,MQSYSP) ACC(CONTROL) \n\n\nRDEFINE MQCMDS ZQS1.STOP.** OWNER(SYS1) \n\nPERMIT ZQS1.STOP.** CLASS(MQCMDS) RESET \n\nPERMIT ZQS1.STOP.** CLASS(MQCMDS) ID(MQSTC,MQSYSP) ACC(CONTROL) \n\n\nRDEFINE MQCMDS ZQS1.SET.** OWNER(SYS1) \n\nPERMIT ZQS1.SET.** CLASS(MQCMDS) RESET \n\nPERMIT ZQS1.SET.** CLASS(MQCMDS) ID(MQSTC,MQSYSP) ACC(CONTROL) \n\n\nRDEFINE MQCMDS ZQS1.CLEAR.** OWNER(SYS1) \n\nPERMIT ZQS1.CLEAR.** CLASS(MQCMDS) RESET \n\nPERMIT ZQS1.CLEAR.** CLASS(MQCMDS) ID(MQSTC,MQSYSP) ACC(ALTER) \n\n\nRDEFINE MQCMDS ZQS1.** OWNER(SYS1) \n\nPERMIT ZQS1.** CLASS(MQCMDS) RESET \n\nPERMIT ZQS1.** CLASS(MQCMDS) ID(MQSTC,MQSYSP) ACC(READ) \n\n\nSETROPTS RACLIST(MQCMDS) REFRESH \n</code></pre> <ol> <li> <p>Select member MQCONN in data set ZQS1.SECURITY.JCL. This JCL defines MQCONN RACF resources required for accessing the queue manager from various sources, e.g., CICS, batch, remote, etc.</p> </li> <li> <p>Submit MQCONN for execution and verify that it completes with a condition code of zero.</p> </li> <li> <p>Select member MQQUEUE in data set ZQS1.SECURITY.JCL. This JCL defines MQQUEUE  RACF resources required for accessing the system related queues.</p> </li> </ol> <pre><code>RDEFINE MQCONN ZQS1.BATCH OWNER(SYS1) \nPERMIT ZQS1.BATCH CLASS(MQCONN) RESET \nPERMIT ZQS1.BATCH CLASS(MQCONN) ID(MQSTC,MQUSERS) ACC(READ) \n\nRDEFINE MQCONN ZQS1.CHIN OWNER(SYS1) \nPERMIT ZQS1.CHIN CLASS(MQCONN) RESET \nPERMIT ZQS1.CHIN CLASS(MQCONN) ID(MQSTC) ACC(READ) \n\nRDEFINE MQCONN ZQS1.CICS OWNER(SYS1) \nPERMIT ZQS1.CICS CLASS(MQCONN) RESET \nPERMIT ZQS1.CICS CLASS(MQCONN) ID(CICSSTC) ACC(READ) \n\nSETROPTS RACLIST(MQCONN) REFRESH \n\nRDEFINE MQQUEUE ZQS1.** OWNER(SYS1) \nPERMIT ZQS1.** CLASS(MQQUEUE) RESET \nPERMIT ZQS1.** CLASS(MQQUEUE) ID(MQSTC) ACC(READ) \n\nRDEFINE MQQUEUE ZQS1.SYSTEM.** OWNER(SYS1) \nPERMIT ZQS1.SYSTEM.** CLASS(MQQUEUE) RESET \nPERMIT ZQS1.SYSTEM.** CLASS(MQQUEUE) ID(MQSTC) ACC(UPDATE) \nPERMIT ZQS1.SYSTEM.** CLASS(MQQUEUE) ID(MQUSERS) ACC(READ) \n\nRDEFINE MQQUEUE ZQS1.SYSTEM.CLUSTER.COMMAND.QUEUE OWNER(SYS1) \nPERMIT ZQS1.SYSTEM.CLUSTER.COMMAND.QUEUE CLASS(MQQUEUE) RESET \nPERMIT ZQS1.SYSTEM.CLUSTER.COMMAND.QUEUE CLASS(MQQUEUE) + \n ID(MQSTC) ACC(ALTER) \nPERMIT ZQS1.SYSTEM.CLUSTER.COMMAND.QUEUE CLASS(MQQUEUE) + \n ID(MQUSERS) ACC(UPDATE) \n\nRDEFINE MQQUEUE ZQS1.SYSTEM.BROKER.** OWNER(SYS1) \nPERMIT ZQS1.SYSTEM.BROKER.** CLASS(MQQUEUE) RESET \nPERMIT ZQS1.SYSTEM.BROKER.** CLASS(MQQUEUE) + \n ID(MQSTC) ACC(ALTER) \n\nRDEFINE MQQUEUE ZQS1.AMQ.MQEXPLORER.** OWNER(SYS1) \nPERMIT ZQS1.AMQ.MQEXPLORER.** CLASS(MQQUEUE) RESET \nPERMIT ZQS1.AMQ.MQEXPLORER.** CLASS(MQQUEUE) + \n ID(MQSTC,MQUSERS) ACC(UPDATE) \n\nRDEFINE MQQUEUE ZQS1.SYSTEM.COMMAND.INPUT OWNER(SYS1) \nPERMIT ZQS1.SYSTEM.COMMAND.INPUT CLASS(MQQUEUE) RESET \nPERMIT ZQS1.SYSTEM.COMMAND.INPUT CLASS(MQQUEUE) + \n ID(MQSTC,MQUSERS) ACC(UPDATE)\nRDEFINE MQQUEUE ZQS1.SYSTEM.CSQUTIL.** OWNER(SYS1) \nPERMIT ZQS1.SYSTEM.CSQUTIL.** CLASS(MQQUEUE) RESET \nPERMIT ZQS1.SYSTEM.CSQUTIL.** + \n CLASS(MQQUEUE) ID(MQSTC,MQUSERS) ACC(UPDATE)\n</code></pre> <ol> <li>Submit MQQUEUE for execution and verify that it completes with a condition code of zero.This completes the configuration of the RACF resources required to start a basic queue manger.</li> </ol> <pre><code>RDEFINE MQQUEUE ZQS1.SYSTEM.MQEXPLORER.REPLY.MODEL OWNER(SYS1) \nPERMIT ZQS1.SYSTEM.MQEXPLORER.REPLY.MODEL CLASS(MQQUEUE) RESET \nPERMIT ZQS1.SYSTEM.MQEXPLORER.REPLY.MODEL + \n CLASS(MQQUEUE) ID(MQSTC,MQUSERS) ACC(UPDATE) \n\nRDEFINE MQQUEUE ZQS1.SYSTEM.PROTECTION.POLICY.QUEUE OWNER(SYS1) \nPERMIT ZQS1.SYSTEM.PROTECTION.POLICY.QUEUE CLASS(MQQUEUE) RESET \nPERMIT ZQS1.SYSTEM.PROTECTION.POLICY.QUEUE CLASS(MQQUEUE) + \n ID(MQUSERS,MQSTC) ACC(UPDATE) \n\nRDEFINE MQQUEUE ZQS1.DEAD.LETTER.QUEUE OWNER(SYS1) \nPERMIT ZQS1.DEAD.LETTER.QUEUE CLASS(MQQUEUE) RESET \nPERMIT ZQS1.DEAD.LETTER.QUEUE CLASS(MQQUEUE) + \n ID(MQSTC,CICSUSER) ACC(UPDATE) \n\nRDEFINE MQQUEUE ZQS1.SYSTEM.COMMAND.REPLY.MODEL OWNER(SYS1) \nPERMIT ZQS1.SYSTEM.COMMAND.REPLY.MODEL CLASS(MQQUEUE) RESET \nPERMIT ZQS1.SYSTEM.COMMAND.REPLY.MODEL CLASS(MQQUEUE) + \n ID(MQSTC,MQUSERS) ACC(UPDATE) \n\nRDEFINE MQQUEUE ZQS1.SYSTEM.CSQOREXX.** OWNER(SYS1) \nPERMIT ZQS1.SYSTEM.CSQOREXX.** CLASS(MQQUEUE) RESET \nPERMIT ZQS1.SYSTEM.CSQOREXX.** CLASS(MQQUEUE) + \n ID(MQSTC) ACC(ALTER) \nPERMIT ZQS1.SYSTEM.CSQOREXX.** CLASS(MQQUEUE) + \n ID(MQUSERS) ACC(UPDATE) \n\nRDEFINE MQQUEUE ZQS1.SYSTEM.PROTECTION.ERROR.QUEUE OWNER(SYS1) \nPERMIT ZQS1.SYSTEM.PROTECTION.ERROR.QUEUE CLASS(MQQUEUE) RESET \nPERMIT ZQS1.SYSTEM.PROTECTION.ERROR.QUEUE CLASS(MQQUEUE) + \n ID(MQUSERS) ACC(UPDATE) \n\nRDEFINE MQQUEUE ZQS1.SYSTEM.DEFAULT.LOCAL.QUEUE OWNER(SYS1) \nPERMIT ZQS1.SYSTEM.DEFAULT.LOCAL.QUEUE CLASS(MQQUEUE) RESET \nPERMIT ZQS1.SYSTEM.DEFAULT.LOCAL.QUEUE CLASS(MQQUEUE) + \n ID(MQUSERS,MQSTC,MQSYSP) ACC(UPDATE) \n\nRDEFINE MQQUEUE ZQS1.DEAD.LETTER.QUEUE OWNER(SYS1) \nPERMIT ZQS1.DEAD.LETTER.QUEUE CLASS(MQQUEUE) RESET \nPERMIT ZQS1.DEAD.LETTER.QUEUE CLASS(MQQUEUE) + \n ID(MQUSERS,MQSTC,MQSYSP) ACC(UPDATE) \n\nRDEFINE MQQUEUE ZQS1.AMSDEMO.** OWNER(SYS1) \nPERMIT ZQS1.AMSDEMO.** CLASS(MQQUEUE) RESET \nPERMIT ZQS1.AMSDEMO.** CLASS(MQQUEUE) ID(MQUSERS) ACC(UPDATE)\nPERMIT ZQS1.AMSDEMO.** CLASS(MQQUEUE) ID(MQSTC) ACC(UPDATE) \n\nRDEFINE MQQUEUE ZQS1.USER1.** OWNER(SYS1) \nPERMIT ZQS1.USER1.** CLASS(MQQUEUE) RESET \nPERMIT ZQS1.USER1.** CLASS(MQQUEUE) ID(USER1) ACC(UPDATE) \nPERMIT ZQS1.USER1.** CLASS(MQQUEUE) ID(MQSTC) ACC(UPDATE) \n\nSETROPTS RACLIST(MQQUEUE) REFRESH \n</code></pre>"},{"location":"streaming-queues/","title":"Creating Streaming queues w/ IBM MQ for z/OS","text":""},{"location":"streaming-queues/#audience-level","title":"Audience level","text":"<p>Some knowledge of MQ or z/OS </p>"},{"location":"streaming-queues/#skillset","title":"Skillset","text":"<p>MQ Administration</p>"},{"location":"streaming-queues/#background","title":"Background","text":"<p>This lab introduces using streaming queues to IBM MQ for z/OS. Streaming queues was released in the IBM MQ product in release version 9.2.3. The function enables you to send near-duplicate messages to a secondary queue, called the streaming queue. </p>"},{"location":"streaming-queues/#overview-of-the-exercise","title":"Overview of the exercise","text":""},{"location":"streaming-queues/#lab-begin","title":"Lab Begin","text":"<p>1)  If not already started, start the MQ Explorer by double clicking on the icon on the image.</p> <p></p> <p>2)  The application should start and show that it is at MQ Version 9.4</p> <p>3)  When the application has started, there may be a selection of queue managers available.  We are interested in connections to queue managers on our z/OS environment. If you do not see connections to a queue manager you have been working with, you can create a connection by right clicking \u2018Queue Managers\u2019 and selecting to \u2018Add Remote Queue Manager\u2026\u2019. You will then fill out all the necessary details for IP address and port number. \u2003 4)  Right click on ZQS1 and select connect.  Please note that the IP address may be different from what is shown here.  </p> <p>The description and command level show that this is a 9.4 queue manager on z/OS.  </p> <p></p> <p>5)  Expand the ZQS1 queue manager \u2013 click on the \u2018&gt;\u2019 beside the name to see the resources defined to this queue manager. </p> <p>6)  Click on the \u2018Queues\u2019 to see the queues that are currently defined.  Please note that the list may differ from what is shown here. For example, you may see the SYSTEM queues or temporary dynamic queues that are currently in use. </p> <p></p> <p>7)  Right click on the Queues under the ZQS1 queue manager and select New-&gt; Local Queue</p> <p></p> <p>8)  The new local queue dialog box should appear, and you will type in the queue name for the streaming target queue.  It should be TEAMXX.STREAM.COPY, replacing the TEAMXX with the TEAM number you have been assigned (it will be TEAM01-TEAM20). After entering the queue name, please click on the \u2018Next\u2019 button.</p> <p></p> <p>9)  On the Change Properties dialog box Please select the \u2018Extended\u2019 option and change the \u2018Sharability\u2019 to \u2018Sharable\u2019 and the \u2018Default input open option\u2019 to \u2018Input Shared as shown and click on the Finish Button.</p> <p></p> <p>10) The object should be successfully created, and the following dialog box should appear.  If you would like to check the \u2018do not show success messages in future\u2019 please feel free.  Please then click the OK button to clear the display. </p> <p>11) You will now define the base queue for streaming.  Right click on the queues tab again and select \u2018New\u2019 -&gt; \u2018Local Queue\u2019 to define the streaming base queue.  It\u2019s name will be TEAMXX.STREAM.BASE, replacing the TEAMXX with your team number (TEAM01 thru TEAM20) . </p> <p></p> <p>12) Click on the Next Button.  There are both Extended and Storage tab changes that will be made.  </p> <p>13) On the \u2018Extended\u2019 tab please change the Sharability and Default Open input option to \u2018Sharable\u2019 and \u2018Input Shared\u2019 as you did for the first queue. </p> <p>14) For those of you familiar with the Storage tab on this dialog box, there have been some changes.  The streaming queue name and quality of service are set here. </p> <p></p> <p>15) The queue name may be selected from the previously defined queues by using the \u2018Select\u2019  Button and choosing the name from the dialog box.  Please select the streaming target queue defined above, you may have to scroll down to find it, and click on \u2018OK\u2019.</p> <p>16) The queue name should now be populated in the dialog box.  Please then select \u2018Must duplicate\u2019 for the 'Streaming quality of service' and click on Finish.</p> <p></p> <p>17) To test, we are just going to put messages to the base queue.  From the queue list right click on the TEAMXX.STREAM.BASE queue (replacing TEAMXX with your team number) and select \u2018Put Test message\u2019.  In the dialog box, please enter a test message and click on the \u2018OK\u2019 button</p> <p></p> <p>18) Please put two more messages onto the queue, varying the contents a bit.  \u2018Test 1, Test2, Test 3\u2019 is just fine.  Click on the \u2018Close\u2019 button to return to the queue list.</p> <p>19) Click on the refresh key, in the upper right side of the queue list box to refresh the list of queues. </p> <p></p> <p>20) You should now see that both the base and copy queues have an equal number of messages.</p> <p>21) At this point you can browse the queues.  Note that the message contents are the same as are the Message IDs on both queues.  </p> <p>BASE:</p> <p></p> <p>COPY:</p> <p></p> <p>22) Testing an Exception \u2013 put inhibit the COPY queue.  From the list of queues, Right click on the TEAMXX.STREAM.COPY (USE YOUR TEAM NUMBER IN PLACE OF TEAMXX) queue and select Properties.  Select \u2018Inhibited\u2019 for put messages, and click on OK.</p> <p></p> <p>23) Attempt to put a message on the TEAMXX.BASE.QUEUE, replacing the TEAMXX with your team ID.  </p> <p></p> <p>24) You should receive a message that you cannot put a message to this queue.</p> <p></p> <p>25) Clicking on the \u2018Details\u2019 shows the reason:</p> <p> \u2003 26) Going back to the BASE queue, change the Streaming Quality of service from \u2018Must Duplicate\u2019 to \u2018Best effort\u2019 and click the OK button.  </p> <p> \u2003 27) Try to put another message to the BASE queue, like what is shown. </p> <p></p> <p>28) That should work, and the depths of the base and copy queues should now be different: </p> <p></p> <p>29) Congratulations!  You have now been able to create and use a streaming, private queue.  </p> <p>30) Now, we will use the queue-sharing group defined on the environment called QSGA to create a streaming, shared queue. </p> <p>31) On MQ explorer, under Queue-sharing groups, you should see QSGA defined. Click the drop-down to see a list of Shared Queues.  </p> <p>32) Unlike private queues, we will need to check which shared storage we should specify for our shared queues. Look under \u2018Coupling Facility Structures\u2019</p> <p>33) We will go ahead and remember TEST1 for our storage needs. Now, create a new shared queue.  </p> <p>34) We will start with defining our streaming queue like so.  </p> <p>35) Under the Storage settings, we must specify our Coupling facility structure name of choice. This is where we will put in TEST1. That is the only additional setting you will need to make for the streaming queue. Press finish.</p> <p>36) Now, we will define our base queue following the same process of creating a shared queue. Here, however, we will specify a streaming queue to point to like so. </p> <p>37) Now, we have defined two shared queues. You should see both in the shared queues list under QSGA.  </p> <p>38) Let\u2019s test them out! Right click the base queue and put a test message on the base queue. </p> <p>39) Once put, you should see the message duplicated on the streaming queue. </p> <p>40) When you navigate to the individual queue managers\u2019 queues, you should see both the shared queues and their messages available to both ZQS1 and ZQS2.</p> <p>LAB FINISHED!</p>"},{"location":"triggering/","title":"Configuring triggering on MQ for z/OS","text":""},{"location":"triggering/#audience-level","title":"Audience level","text":"<p>Some knowledge of MQ, z/OS, CICS</p>"},{"location":"triggering/#skillset","title":"Skillset","text":"<p>MQ Administration</p>"},{"location":"triggering/#background","title":"Background","text":"<p>The purpose of this lab is to give you a hands-on introduction to triggering. Triggering can be used to:</p> <ul> <li>Automatically start a channel when messages arrive on its transmission queue.</li> <li>Automatically start a CICS transaction to process messages on a queue.</li> </ul> <p>This lab walks you through an example of the latter, using a simple example CICS program called QCOPY. The QCOPY program is executed from the QCPY transaction. When the necessary conditions are met, QCPY is triggered (or automatically started) to move messages from one queue to another in MQ, applying a message property to each message. </p>"},{"location":"triggering/#lab-overview","title":"Lab Overview","text":"<p>I. Defining MQ Objects for Triggering</p> <p>II. Configuring CICS components</p> <p>III. Testing it all out</p> <p>In part I and II of the lab, we will walk through the configuration for triggering, and in part III, we will validate it works. </p> <p>By the end of this lab, you should have an understanding of how triggering is configured, so you can implement it for our own use cases.</p> <p>The sample requires a currently supported version of IBM MQ and CICS. You can find the COBOL source code for the QCOPY program in ZQS1.COBOL.SOURCE if you are using the MQPLEX lab environment. If you need access to a lab sysplex, contact the Washington Systems Center or your IBM technical sales contact.</p>"},{"location":"triggering/#procedure","title":"Procedure","text":""},{"location":"triggering/#i-defining-mq-objects-for-triggering","title":"I. Defining MQ Objects for Triggering","text":"<ol> <li> <p>Navigate to the MQ web console. You can also use MQ Explorer or MQSC commands via PCOMM.</p> </li> <li> <p>Create the 5 local queues below, using the pictures to guide which parameters to set.</p> <p>QCPY.CONTROL - This queue contains the message used to start the QCPY transaction. For QCPY, the message payload will contain, in comma delimited format: the number of messages to be copied, the source queue, the target queue </p> <p>QCPY.INPUT - The source of the messages to be copied. </p> <p>QCPY.OUTPUT \u2013 The target for the copied messages. </p> <p>QCPY.STATUS \u2013 The queue which will hold the status messages, reporting on success or failure. </p> <p>CICS.INITQ - The initiation queue to connect CICS to MQ for triggering purposes </p> </li> <li> <p>Next navigate to MQS1 PCOMM.</p> </li> <li> <p>Navigate to SDSF from the ISPF main menu.</p> </li> <li> <p>Define a process using the MQSC command below on SDSF. A process is an MQ object that defines an application to the MQ Queue Manager. MQ will use the process definition to identify our CICS application, QCPY, to be started by a trigger monitor.</p> </li> </ol> <p>a.  Here, we\u2019ll specify CICS as our application</p> <p>b.  'QCPY' is our application ID. This is the transaction name in CICS.</p> <p>c.  Environment data is status queue which tells us what happen at the end of the process.</p> <p>QCPY.PROCESS </p>"},{"location":"triggering/#ii-configuring-cics-components","title":"II. Configuring CICS components","text":"<ol> <li> <p>Now, ensure CICS is running. Test this via SDSF from the ISPF main menu.</p> </li> <li> <p>Navigate to \u2018da\u2019 once in the SDSF menu to see active users.</p> </li> <li> <p>Set the prefix to * so we can see all active users with the command \u2018prefix *\u2019. Then, using the F7 and F8 keys, navigate to see if CICS is running. You should see something like this:</p> </li> </ol> <p></p> <ol> <li> <p>If there is no CICS region active, you will need to start the CICS region with command \u2018start MQS1CICS\u2019</p> </li> <li> <p>Once you've validated CICS is running, navigate to the CICS display by starting another MQS1 PCOMM session. From the main screen, use the MQS1CICS command and press enter.</p> </li> </ol> <p></p> <ol> <li> <p>From the CICS main screen, hit tab once, then type in CKQC. This is the MQ CICS transaction CKQC. This transaction makes it possible to monitor and control the interface between MQ and CICS.</p> </li> <li> <p>Currently, no one is listening, so we\u2019ll need to add a listener to CICS01.INITQ. From z/OS CICS screen, navigate to CKQCM0 by typing in the command.</p> </li> </ol> <p></p> <ol> <li>This screen should pop up. </li> </ol> <p></p> <ol> <li>Enter the tab or tab button with your cursor next to the Connection option. The following menu will pop up. Type in option 1 and press enter.</li> </ol> <p></p> <ol> <li> <p>Enter in your appropriate queue manager name and initiation queue name and press enter.</p> </li> <li> <p>Press F12 to return to the main menu. Move your cursor next to CKTI option and press enter. The following menu will pop up. Type in option 1 and press enter.</p> </li> <li> <p>Enter in your appropriate queue queue name and press enter.</p> </li> </ol> <p></p> <p>This step initiates the CKTI transaction, which is what controls the CICS trigger monitor.</p> <p></p> <ol> <li>F12 to escape. If you display your connection or CKTI using the menu options, you should see the appropriate initiation queue linked, similarly to the examples below. You will also now see that your CICS.INITQ in MQ has a open input count of 1.</li> </ol> <p>Connection display: </p> <p>CKTI display: </p>"},{"location":"triggering/#iii-testing-it-out","title":"III. Testing it out","text":"<ol> <li> <p>Now, we have all of our necessary objects (queues and process) configured, we have our connection between MQ and CICS configured, so we are all set to test out triggering. </p> </li> <li> <p>Navigate to the web console. Once in the web console, navigate to the QCPY.INPUT queue. </p> </li> <li> <p>Place several test messages on the QCPY.INPUT queue. Place at least 5 messages on the queue. The message payload can be any text you'd like.</p> </li> <li> <p>Now, put a test message on QCPY.CONTROL. The message MUST be in the format below: </p> </li> </ol> <p><code>2,QCPY.INPUT,QCPY.OUTPUT</code> where 2 is the number of messages you want to copy, QCPY.INPUT is the input queue, and QCPY.OUTPUT is the output queue.</p> <p>This message requests that MQ copies 2 messages from QCPY.INPUT to QCPY.OUTPUT. After you submit this, check it worked by looking at the queue depths of QCPY.INPUT an QCPY.OUTPUT. QCPY.INPUT should have 2 less messages, QCPY.OUTPUT should have 2 more messages.</p> <ol> <li>Next, look at the QCPY.STATUS messages. You should see a new message on the queue confirming the QCPY was successful:</li> </ol> <p><code>MESSAGES COPIED  =  000002  FROM QUEUE =       QCPY.INPUT TO QUEUE =         QCPY.OUTPUT</code></p> <ol> <li>Congratulations! You have successfully used a CICS application for triggering! To recap, we created all the necessary objects and ran an experiment to copy messages from our source queue to our target queue, seen below.</li> </ol> <p></p>"},{"location":"Blog/CF%20calls%20Generated%20by%20an%20MQGET%20Query/","title":"CF calls Generated by an MQGET Query","text":"<p>Lyn Elkins</p> <p>I am not an SQL expert, which everyone should know since I only recently discovered how to use VIEWs to make my tasks a bit easier. Any SQL I write and share should be reviewed with that in mind. These queries are also written based on the column names assigned by MQSMFCSV, which will be different is using another SMF interpreter. This is also considered open source and should be treated as such. It is presented as-is and there is no implied or stated support.</p> <p>Years ago, I began using the WQ records to provide summaries of queue level activity I briefly looked into the breakdown of Coupling facility calls that were being made. I was told by people with the correct accent that I really did not need to know about those fields, and for years I did not. However, as those people who assured me that I didn\u2019t need to know are gone, I ended up having to look into these fields and found that yes we do need examine those records in that level of detail because it led to an explanation for some behavior that has been observed several times now by customers that are heavy users of shared queues in various patterns. We also uncovered some gaps in the data collection that are being addressed by the development lab. This is complex performance problem determination, looking into things that are not observed everything is running well.</p> <p>If you have not read the articles on Task Records and how they are associated, Using Views, and symptoms that led to finding this issue (which has already been applied to some other customer data), I\u2019d recommend a quick overview of those first. The SQL development took several iterations to get meaningful information. We were fortunate to have customer data from days where the processing flowed normally and where they had problems. How often have I said, \u201cIt is hard to spot abnormal when you don\u2019t know what normal looks like\u201d? More than I can count certainly. In this case it was vital to finding the issues.</p> <p>First it was troubling that the overall volume of requests was not noticeably higher on some of the days where there were issues reported. That\u2019s unusual, as many of the problems we see are related to volume changes. When we started analyzing the traffic in the queues themselves, from the Task associated WQ records, we did find changes in volumes on individual queues. We also found that the overall mix of messages was skewed towards one queue on one structure during the problem periods. And we could see after the individual queue analysis that one queue had an extremely low valid get percentage when those periods began. What was also interesting, was that we could see the percentage of valid gets fluctuate on this queue even in \u2018good\u2019 periods at times almost dropping to the same level as when there were noted problems. We then started looking at the types of MQGETs being done against the shared queues in this QSG. That led to looking at the actual CF calls being made, and that made all the difference. The query used was just for the GET processing being done. When we tried to combine the PUT processing into the same query we had far too many columns to be contained in a normal spreadsheet. As it turned out, we did not need all of the calls to the CF that the MQGETs resolved into, so we did simplify the query to look for the \u2018READLIST\u2019 and \u2018GETMOVE\u2019 CF requests in our comparisons.</p> <p>This shorter version of the \u2018What calls are being made\u2019 query looks like what is shown below, and is included in this git repository as CFGETsBreakDown.txt.</p> <p>What we found was simple, the volume of requests skewed toward a particular type of processing when the issue began \u2013 that was to do gets by a message selector. This is more work for the queue manager as it has to read thru all the messages on the queue looking for the right match. Unlike private queues where there is a \u2018messages skipped\u2019 count there is no equivalent for shared queues. Also the use of message selectors only shows up in the WQ records when the queue is opened, and as these were very long running tasks at first glance it looked like request to the problem structure and queue were not using selectors. It was only when we looked at the actual CF calls that we could see that the processing for a particular queue on a specific structure that was different. Each MQGET was resolving into anywhere from a few (during non-problem periods) to several thousand \u2018READLIST\u2019 requests (during problem periods) to the CF structure. This was because as the queue got deeper more READLISTs were required to scroll thru all the messages. To make matters worse the applications issuing the MQGETs had a very short timeout (in seconds), but the messages themselves were not expiring for minutes. That meant that messages were building up on the queue that would never be retrieved while at the same time new messages were being put. The solution was to alter the processing to use an indexable field rather than a message selector, to set a message expiration closer to the value used for the MQGET, and to set the queue manager expiration interval to run more frequently on all queue managers in the QSG. The application changes took more time to implement, so to help prevent the issue from impacting other application and other processes that were part of this application, the queue was moved to its own CF structure so there would be less competition for resources and the queue manager expiry interval was set on all queue managers to help clean up the queue more frequently.</p> <p>It was also interesting to discover the issue was also present during period where there had not been a detected problem. There was a specific volume of failing MQGETs before the impact was detected by the application and users \u2013 when we reviewed some of the \u2018good\u2019 processing periods we also found failing MQGETs, and at times it seemed to border on the problem threshold. This was a classic problem waiting to happen.</p> <p>EXPORT TO \"E:\\customer\\Query_Results\\GETTasksByQ.csv\" OF DEL MODIFIED BY COLDEL, DECPT.</p> <p>SELECT</p> <p>CHAR(WTID.DATE) AS DATE1,</p> <p>WTID.TIME AS TIME1,</p> <p>WTID.LPAR AS LPAR,</p> <p>WTID.QMGR AS QMGR,</p> <p>WTID.WTAS_CORRELATOR AS CORRELID,</p> <p>WTID.CHANNEL_NAME AS CHL_NAME,</p> <p>WTID.Channel_Connection_Name AS CONNECTION_NAME,</p> <p>CHAR(WTAS.Commit_Count) AS COMMIT_COUNT,</p> <p>CHAR(WTAS.Commit_ET_us) AS COMMIT_ET,</p> <p>CHAR(WTAS.Commit_CT_us) AS COMMIT_CPU,</p> <p>CHAR(WTAS.Backout_Count) AS BACKOUT_COUNT,</p> <p>CHAR(WTAS.Backout_ET_us) AS BACKOUT_ET,</p> <p>CHAR(WTAS.Backout_CT_us) AS BACKOUT_CPU,</p> <p>CHAR(WTAS.START_TIME_DATE) AS TASK_START_DATE,</p> <p>CHAR(WTAS.START_TIME_TIME) AS TASK_START_TIME,</p> <p>CHAR(CF_STE_CALL_COUNT) AS SINGLE_ENTRY_CALL_COUNT,</p> <p>CHAR(CF_STM_CALL_COUNT) AS MULTIPLE_ENTRY_CALL_COUNT,</p> <p>CHAR(CF_STE_REDRIVE_COUNT) AS SINGLE_ENTRY_REDRIVES,</p> <p>CHAR(CF_STM_REDRIVE_COUNT) AS MULTIPLE_ENTRY_REDRIVES,</p> <p>CHAR(CF_STE_ELAPSED_US) AS SINGLE_ENTRY_ET,</p> <p>CHAR(CF_STM_ELAPSED_US) AS MULTIPLE_ENTRY_ET,</p> <p>WQ.Open_Name AS OPEN_NAME,</p> <p>WQ.Base_Name AS BASE_NAME,</p> <p>CHAR(WQ.GET_COUNT) AS GET_COUNT,</p> <p>CHAR(WQ.TOTAL_VALID_GETS) AS VALID_GET_COUNT,</p> <p>CHAR(WQ.GET_CT_US) AS GET_CPU,</p> <p>CHAR(WQ.GET_ET_US) AS GET_ET,</p> <p>CHAR(GET_DEST_ANY_COUNT) AS MQGET_ANY_COUNT,</p> <p>CHAR(GET_DEST_SPECIFIC_COUNT) AS MQGET_SPECIFIC_COUNT,</p> <p>CHAR(MAX_DEPTH) AS MAX_QUEUE_DEPTH,</p> <p>CHAR(SELECT_COUNT) AS SELECTOR_COUNT,</p> <p>CHAR(SELECT_MAX_LENGTH) AS SELECTOR_MAX_LEN,</p> <p>CHAR(CFCOUNT_GET_READLIST) AS CFREADLIST_COUNT,</p> <p>CHAR(CFSYNC_GET_READLIST) AS CFSYNC_READLIST_COUNT,</p> <p>CHAR(CFSYNC_GET_READLIST_ET) AS CFSYNC_READLIST_ET,</p> <p>CHAR(CFASYNC_GET_READLIST) AS CFASYNC_READLIST_COUNT,</p> <p>CHAR(CFASYNC_GET_READLIST_ET) AS CFASYNC_READLIST_ET,</p> <p>CHAR(CFCOUNT_GET_MOVE) AS CFGETMOVE_COUNT,</p> <p>CHAR(CFSYNC_GET_MOVE) AS CFSYNC_GETMOVE_COUNT,</p> <p>CHAR(CFSYNC_GET_MOVE) AS CFSYNC_GETMOVE_ET,</p> <p>CHAR(CFASYNC_GET_MOVE) AS CFASYNC_GETMOVE_COUNT,</p> <p>CHAR(CFASYNC_GET_MOVE) AS CFASYNC_GETMOVE_ET,</p> <p>'2' AS Row_ID</p> <p>FROM QSGQSGA_WTID AS WTID, QSGQSGA_WTAS AS WTAS, QSGQSGA_WQ WQ</p> <p>WHERE ( WTID.WTAS_Correlator = WTAS.Correl</p> <p>AND WQ.CORRELATION = WTAS_Correlator</p> <p>AND WTID.DATE = WTAS.DATE</p> <p>AND WQ.Date = WTAS.Date</p> <p>AND WQ.TIME = WTAS.TIME</p> <p>AND WTAS.TIME = WTID.TIME</p> <p>AND WTAS.QMgr = WTID.Qmgr</p> <p>AND WQ.QMGR = WTAS.QMgr</p> <p>AND WQ.CF_STRUCTURE &lt;&gt; ' '</p> <p>AND WQ.GET_COUNT &gt; 0 )</p> <p>UNION</p> <p>SELECT</p> <p>' Date ',</p> <p>' Time ',</p> <p>' LPAR ',</p> <p>' QMGR ',</p> <p>' Task Correlation ID ',</p> <p>' Channel Name ',</p> <p>' Channel Conection Name ',</p> <p>' Commit Count ',</p> <p>' Commit Elapsed Time ',</p> <p>' Commit CPU Time ',</p> <p>' Backout Count ',</p> <p>' Backout Elapsed Time ',</p> <p>' Backout t CPU Time ',</p> <p>' WTAS Start Date ',</p> <p>' WTAS Start Time ',</p> <p>' WTAS Single Entry CF Call Count ',</p> <p>' WTAS Multiple Entry CF Call Count ',</p> <p>' WTAS Single Entry Redrive Count ',</p> <p>' WTAS Multiplee Entry Redrive Count',</p> <p>' WTAS Single Entry Elapsed Time ',</p> <p>' WTAS Multiple Entry Elapsed Time ',</p> <p>' Queue Open Name ',</p> <p>' Queue Base Name ',</p> <p>' Get Count ',</p> <p>' Valid Get Count ',</p> <p>' Get CPU ',</p> <p>' Get Elapsed Time ',</p> <p>' Get Destructive Any ',</p> <p>' Get Destrcutive Specific ',</p> <p>' Maximum Queue Depth ',</p> <p>' Get Selector Count ',</p> <p>' Get Selector Max Length ',</p> <p>' Get Readlist Count ',</p> <p>' Get Sync Readlist Count ',</p> <p>' Get Sync Readlist Elapsed Time ',</p> <p>' Get ASync Readlist Count ',</p> <p>' Get ASync Readlist Elapsed Time ',</p> <p>' Get Getmove Count ',</p> <p>' Get Sync Getmove Count ',</p> <p>' Get Sync Getmove Elapsed Time ',</p> <p>' Get ASync Getmove Count ',</p> <p>' Get ASync Getmove Elapsed Time ',</p> <p>'1' AS Row_ID</p> <p>FROM SYSIBM.SYSDUMMY1 ORDER BY Row_ID</p> <p>;</p>"},{"location":"Blog/MultipleQSGAndViews/","title":"Multiple QSG And Views","text":"<p>Over the past year we have seen more customers with multiple queue sharing groups (QSG) in production. Managing the SMF data is more challenging when this is the case, especially when there are multiple QSGs that have the same structure names (we see this a lot) and the same shared queue names. This is because most of the MQ SMF data is completely queue manager centric. Except for the QCCT (channel initiator statistics) and the new QQST (queue statistics records) this important information does not appear in the others. So, when I am looking at the MQ reported Coupling Facility statistics for a structure named APP1, if that structure is in multiple QSGs, the simple query we have commonly used those results will be misleading. Misleading data leads to errors when trying to track down workload skewing and performance problems. And while those of us using this hope that the QSG name gets added to more records in the future, what do we at the WSC do to address this in the meantime?</p> <p>Up until 2022, I hand coded SQL. Then Dorothy coded up Python scripts to generate the 'usual suspects' queries for our health check work. To use those in situations where there are multiple queue sharing groups, we have then had to replicate and tailor those scripts to pull the data for the queue managers in individual QSGs. And we have been in situations where the customer's documentation about QSG members has not been kept up to date - new queue managers have been added, older queue managers have been retired, or (even worse!) been moved to a different QSG.</p> <p>Looking for simpler, more efficient, less subject to error methods, and because these multi-QSGs have become more common, we talked about reconfiguring the python scripts, etc. But as I was working with data over this past week, and Dorothy was fighting fires on another front, I decided to try using Db2 Views to separate the queue managers into the QSGs. I am not an SQL expert, and as we all know the IBM documentation can be quite effective when you know what you are looking for and painful to follow when you are searching for the answers to \u2018this is how you do this.\u2019 So, in case others are in this same position, I felt like it was time to write this up. The first thing to do was figure out which queue managers are in which queue sharing group. After loading the data processed by MQSMFCSV into Db2 we run this very simple SQL:</p> <p>The results from this query look something like this: What this shows is that there are two queue sharing groups represented each with 6 queue managers, and 7 standalone queue managers. Using this information, I created views over all the tables generated by MQSMFCSV. The pattern looks like this:</p> <p>[INSERT IMAGE]</p> <p>A view for the tables for the standalone queue managers was also created. What this allowed us to do was use the views to isolate the activity reported on the individual QSGs, making the queries simpler, more readable, and giving us more accurate data about the use of the CF, Db2 and SMDS. It also allowed us to review the queue and task activity by QSG, giving better insight into their use as well.</p> <p>To illustrate the simplification, the SQL WHERE clause we had to compose to retrieve the QEST data (the queue managers calls to a structure data) before creating the views looked like this: After creating the views, the same Where clause looks like this:</p> <p>[INSERT IMAGE]</p> <p>This does not seem like much, but using views has once again saved much needed time and prevented typos. And it means that we are looking at data from a single queue sharing group, that we do not have the possibility of comingling data from multiple QSGs and can evaluate more complex situations more accurately.</p> <p>Please note that all samples considered open source, feel free to use them but they are provided AS-IS. There is no guarantee of support. </p>"},{"location":"Blog/SMF%20data%20gathering%20suggestions/","title":"SMF Data Gathering Suggestions","text":""},{"location":"Blog/SMF%20data%20gathering%20suggestions/#another-wrinkle-suggestions-for-updating-smf-data-gathering","title":"Another Wrinkle! Suggestions for updating SMF data gathering","text":""},{"location":"Blog/SMF%20data%20gathering%20suggestions/#author-lyn-elkins","title":"Author: Lyn Elkins","text":"<p>Over the weekend I was processing customer data from a customer we work with regularly, and low and behold I noticed something I probably should have seen before.  This is that information.  Names have been changed to protect the participants.</p> <p>When we receive MQ for z/OS SMF data from customers, after we process it thru MQSMFCSV and load it to Db2 we run a couple of standard queries.  First to get the names of the LPARs and QMGRs in the data, we use this output to drive a python script to generate our \u2018standard queries\u2019 for each queue manager.  Second, we run a query to get the Queue Sharing Group names from the Channel Statistics (the class 4 statistics).  There are some specialized queries we run against the QSG Views we create on the tables so we can make sure we are not co-mingling data from separate QSGs.  We do ask for all queue managers to have all the classes of Statistics for evaluation, because the channel statistics are the only SMF records that currently contain the QSG. We have asked that the QSG be added to all MQ SMF records.  </p> <p>An example of when this data gets confusing is that we see many customers with multiple QSGs in production, but with the same structure names in each QSG.  This works because the QSG knows the structure name as QSGNCFStructure, where QSGN is the QSG name and CFStructure is the structure name as known to MQ.  There may be several APP1 structures in different Coupling Facilities, but they are differentiated by the QSG name.  This lack of differentiation in the MQ SMF data, especially in the case of the CF statistics,  has caused confusion and possibly bad recommendations in the past.  </p> <p>If QSG QSGA has structure APP1 and QSGB also has structure APP1 \u2013 they are different to the QSGs and QMGRs in each, but the MQ SMF statistics currently just show the data for \u2018APP1.\u2019  We now have seen another level of potential confusion when looking thru customer data. </p> <p>In one of this customer\u2019s QSGs there were several queue managers, only half of which seem to have the Channel Statistics turned on.  So, when I initially ran the query to get the list of QSG members, the list did not include all the queue managers in that group.  I was accidentally reviewing Queue data (the WQ records for a queue manager) and saw that a queue manager did not show up on the QSG list because of this.  I had to go back and do some re-work to pull in the correct queue managers.  </p> <p>I have submitted an IBM Idea for this issue, and I would appreciate you looking at the Idea, making suggestions where I may have missed something, and voting if you feel it would help you as well: Make it simpler to turn on SMF capture - Link </p> <p>For years it has been traditionally difficult to turn on the various levels of SMF data gathering.  For example, when writing our data collection for MQ on z/OS there are 4 pages of instructions, longer than Db2s which is asking for more different kinds of data.  I have been through the instructions multiple times with customers and too often find that I am still missing specific queue data for a number of queues because they or their models are delivered with accounting and monitoring turned off.  This makes figuring out which of the millions of tasks captured are not showing the full compliment of queues used complex.  We try using the \u2018other\u2019 counts that show up in the WTAS (Task Statistics Records) \u2013 but those can be many different types of activity, and we need to know which queues are in use.  This is likely to be a carry over based on the past costs of gathering this critical information and to allow customers more flexibility in their data gathering.  However, it often prevents those of us in various roles that need to look at this data from getting a complete picture. </p> <p>Checking every queue for the correct settings is also cumbersome for our customers.  Getting customers to change individual queue and channel setting when we are trying to chase down a problem is time-consuming and often painful.  Especially if they have very strict change control, as they should.    </p> <p>My suggestion is simple, change the queue manager/chinit level (ZPRM) settings to include option of \u2018gather all accounting\u2019 or \u2018gather all statistics\u2019 or \u2018gather everything\u2019 - overriding individual queue and channel level settings.  We would get far more compliance and it would be easier for customers to understand.   The default should be \u2018gather all statistics.\u2019   </p> <p>In a subsequent update I added this: Greetings, another related idea related to our ability to rely on the data for correct customer environment information.  Perhaps this switch should be a QSG related field.  Over the weekend I found a customer's data showed use of some CF resources by QMGRs that were not from our generated list of QSG members based on the QSG name from the Channel statistics records.  While we ask customers to turn on all the collection for all queue managers in the QSG, in haste some folks forget this step.  But for ease of use and ease of compliance a switch or switches to turn on all SMF collection that can be used dynamically would have a lot of benefit for both customers and those engaged in the task of trying to find performance issues, patterns of behavior (people, any AI enhanced tool), etc. </p>"},{"location":"Blog/Symptoms%20that%20led%20to%20PD/","title":"Symptoms that led to problem determination","text":"<p>The following list of symptoms led us to an underlying problem of application requests flooding a coupling facility.</p> <p>1) MQ Statistics Symptom - The number of message managers gets was much lower than the number of data manager gets.</p> <pre><code>a. As we have noted, the message manager counts the number of MQGET requests that\ncome into the queue manager. The data manager reports the number of gets that are\nused to fulfill the request. When the Data Manager Gets exceeds the Message Manager\nGets, that is an early and high-level indicator of message selector use or of queue not\nbeing indexed properly. When the MM GET count is higher than the DM GET count that\nis an indication that GETs are being done against empty queues, so the request is not\npassed to the DM.\n\n    i. Note \u2013 for private queues, a count of skipped messages is kept in the WQ\n    records. There is no equivalent for shared queues.\nb. The Coupling Facility statistics records, QEST, showed a dramatic rise in the number of\nCoupling Facility redrive requests over the problem intervals.\n\n    i. True for both single entry and multiple entry requests, a relatively small number\n    of redrives is normal but when they exceed 20% during an interval, we try to\n    look into it.\n</code></pre> <p>2) Coupling Facility Symptoms</p> <pre><code>a. High CF CPU use \u2013 high CPU use can be from any number of things including workload\nspikes. However, it has been observed in several instances of scrolling thru queues at\nseveral customers. It requires examination of the Coupling Facility Activity Report, or its\nequivalent, based on the RMF data.\n\nb. Sub-channel waits reported \u2013 Again, not a specific symptom as there can be a few\nreasons for this to happen. One is an increase or spike in the number of requests to a\nspecific CF structure, causing contention on the subchannels that provide\ncommunication between the LPAR and CF. Other reasons we have seen this happen is\ndue to CF Links being taken offline, typically accidentally, and changing hardware\nconfigurations. Sub-channel waits are also reported as part of the Coupling Facility\nActivity Report\n</code></pre> <p>3) MQ Task Accounting Symptoms:</p> <pre><code>a. The percentage of valid gets was extremely low for at least one of the queues using the\nproblem structure. In this case the percentage of valid gets for all the queues on the\ntroubled structure was less than 1% in total and the GET count was very high for at least\none queue on that structure. That is cause for concern in most environments. Please\nsee \u2018comparing valid MQGETs\u2019 below for additional information.\n</code></pre> <p>4) Many MQGETs were for specific messages.</p> <pre><code>a. In the WQ records contains counts of each type of MQGET; destructive get for any\nmessage (FIFO), destructive get for a specific message, browse for any message (FIFO),\nand browse for a specific message.\n\nb. There was no index defined for the shared queue that exhibited the most specific\nmessage gets on the problem structure.\n\nc. As described above, these long running TXs do not have the \u2018select count\u2019 indicator set\nfor any interval that does not contain an open.\n</code></pre> <p>5) Comparing valid MQGETs with those that do not return data in the WQ records. As stated above, the number of valid gets was extremely low during the problem period. However, this symptom can be caused by application style choices and may not be easy to remedy. Some issues include:</p> <pre><code>a. Polling applications \u2013 often these are applications that do not use triggering or gets with\na wait interval, they repeat the MQGETs until a message is returned. This particular\npattern can be made worse by client applications that are poorly behaved (connect, do\none thing, disconnect, repeat). It is also the typical implementation pattern from some\napplication enablement tools, so programmers may not even be aware that this is what\nis happening.\n\nb. Gets with waits \u2013 MQ will signal all instances of an application in a wait state when a\nnew message arrives on a queue. This causes the MQGET request to be resent (as if\nnew). This can lead a high number of \u2018empty Gets\u2019 if the messages are being put at a\ncomparatively slow rate when compared to how quickly messages can be retrieved.\n\nc. Too many getting application instances \u2013 tuning the number of application instances to\npeak periods can lead to a lot of empty gets during the slower times.\n\nd. Related to c is the fact that we, the WSC, have seen customers adding instances of the\ngetting applications to address response slowdowns, making the problem much worse.\nWhen the slowdown is caused by too few instances of a processing application, adding\nmore helps. When it is caused by internal contention over a particular resource, more\ninstances make the problem worse.\n\ne. The last symptom we found was when we examined the calls to the CF to fulfill the\nrequests. I had never examined the data at this low a level before, having been told\noften enough that \u2018you should never need to.\u2019\n</code></pre> <p>The CF calls made depend on the type of MQGET being done. A simple FIFO MQGET is likely to only use a GETMOVE request to the CF \u2013 returning the next message available. An MQGET using a message property match is more complex. What we found was that the requests to get a message by a selector match issued one-to-many READLIST requests for each GETMOVE (the real get of the selected message). When things were running well, the ratio of READLISTs to GETMOVEs was no more than 3 to 1. Most often it was 1 to 1. During the problem period, the number of READLIST requests became exponentially higher than the GETMOVEs. The READLIST requests return a buffer of messages to the queue manager and will set a cursor on the queue to indicate the starting point for the next READLIST in case none of the messages in this group match the selection criteria. The number of messages that can be returned by the READLIST depends on the size of the buffer, the size of the messages, and any \u2018congestion\u2019 that may be taking place within the structure itself. With an increasing depth on the queue, the number of READLISTs increased because the GETs were requesting newer messages. The older messages had an expiration set and that was being honored, the problem would have been much worse if that were not the case. However, the message expiration was set much higher that the MQGET wait expiration, so there were messages on the queue that were never going to be matched and were being read multiple times.</p> <p>At the same time, there were applications continuing to put messages to the \u2018problem\u2019 queue, and other queues with active puts and gets on the same structure. None of the other queues had an extremely high volume at the time, but there was other activity on the CF structure.</p> <p>This is a good example of a problem waiting to happen \u2013 none of the processing was new or changed by the application or the queue manager. It reached a critical mass due to increased volume of certain types of requests, contention on the queue, and contention on the structure hosting that queue. In my next article I will publish the query that assisted us in finding the CF calls that were used. </p>"},{"location":"Blog/Task%20record%20information/","title":"Task Record Information","text":"<p>Task Records information</p> <p>A question we have already started receiving is whether we shall continue to need the Accounting class  3 records once customers have fully implemented the new queue statistics that became available in MQ  V9.3.3. The answer is simply yes, and we have a good example of why that detailed level of information  may be needed in this post. We have now found that there are occasions when we must look at the  details the requests made to Coupling Facility when using shared queues. This post is the beginning of  how we examined the queue manager conversion from an MQ API request to the CF requests. That  information is only found in the WQ records, part of the Task Accounting data.</p> <p>1) At the WSC we use MQSMFCSV to convert the MQ SMF records (all types and sub-types) to CSV  files and to generate the DDL for Db2. We use the DDL to build the tables within a Db2  database, then load the CSV files into the appropriate tables. The names of the fields used in  this document are those set by MQSMFCSV. If you are using a different SMF record parser or a  database other than Db2, this information will have to be translated into the formats used by  the different tools.</p> <p>2) A task to MQ is created for a connection to the QM from any type of workload (CICS, IMS, Db2,  RRS, TSO, Batch, CHIN, or client connections via the channel initiator). A task will always have a  task ID associated with it, it is a 33 byte character field that is used to correlate the WTID, WTAS  and WQ records associated with the task. The field has different names based on the record and  is called WTAS_CORRELATOR in the WTID, or task identification record, CORREL in the WTAS, or  Task Statistics record, and CORRELATION in the WQ or queue information record(s).</p> <p>3) The task records are always created at task end and may also be created at the SMF intervals for  tasks that span more than one SMF interval. These are known as Long Running Tasks (LRT). The  accounting SMF interval is controlled by the ACCTIME in the ZPRM member and defaults to -1 or  produce Accounting SMF at the same intervals as the Statistics.</p> <p>4) The WTID record contains information that remains consistent for the duration of the task, with  the exception of the \u2018Date and Time\u2019 fields. It also contains some potentially very useful  information like the connection name and application information.</p> <p>5) The WTAS record (tasks statistics) contains the date and time of the interval, the start date and  time for the task, and task specific data that we often use for performance issues \u2013 including  latching information and CF calls that are at the task level.</p> <p>6) The WQ records (task queue records) contain the interval data and time, and very detailed  information about the queue\u2019s disposition and use by this task. It includes specifics about the  MQAPI calls not found elsewhere and calls to the CF to satisfy the API request. The queue  statistics added with IBM MQ for z/OS 9.3.3 does not include this detailed breakdown of the API  requests.</p> <p>7) LRTs require special treatment, for example after the first set of records for the LRT, counts are  set to zero at SMF intervals.</p> <p>a) If you do not have the \u2018first instance\u2019 of the task in the data being examined, some  information may be hard to discern. For example, the use of selectors on MQGET processing.  The Selector count and length are set at MQOPEN time, and when an open is only done at the  start of a task subsequent records do not clearly indicate selector use. However, if all MQGET  requests show that they are for specific records and the queue is both shared and non-indexed  it is usually safe to assume that selectors are in use. </p> <p>b) Note that if an MQGET is done against a shared queue , has a 'typical' match option, and the  queue is not indexed properly; that MQGET will fail with a 2207 (CORREL_ID_ERROR).</p> <p>c) If the information is needed from start to finish for a particular task, the Accounting Class(3)  data should be started at queue manager start-up, or before the task is started and continue  until the task has ended, or until the next restart of the queue manager.</p> <p>8) To get the correct records to align for LRTs, several fields must be matched between the three  tables. They are listed here with the name of the table included as a qualifier: WTID.WTAS_CORRELATOR, WTAS.CORREL, WQ.CORRELATION WTID.DATE, WTAS.DATE, WQ.DATE WTID.TIME, WTAS.TIME, WQ.TIME WTID.LPAR, WTAS.LPAR, WQ.LPAR WTID.QMGR, WTAS.QMGR, WQ.QMGR</p> <p>9) The WHERE clause in queries to associate the correct WTID, WTAS and WQ records looks  something like this: WHERE (WTID.WTAS_CORRELATOR = WTAS.CORREL AND WTAS.CORREL = WQ.CORRELATION AND  WTID.DATE = WTAS.DATE AND WTAS.DATE = WQ.DATE AND WTID.TIME = WTAS.TIME AND  WTAS.TIME = WQ.TIME AND WTID.LPAR = WTAS.LPAR AND WTAS.LPAR = WQ.LPAR AND WTID.QMGR = WTAS.QMGR AND WTAS.QMGR = WQ.QMGR )</p> <p>10) The WHERE clause may be extended to return rows for just about anything, including a specific  date, queues that are on a specific structure (WQ.CF_STRUCTURE), a specific queue, or as in this  investigation looking for all queues hosted on a designated structure and where the get count  (WQ.GET_COUNT) is greater than zero.</p> <p>11) If your investigation includes data from more than one queue sharing group, defining views for  each QSG is necessary when the same structure names are used by more than one QSG. Please  see the previous article for directions on setting up those views.</p> <p>12) All MQ API requests are broken down into one or more calls to the coupling facility, depending  on the attributes of the request. This activity is reported in the WQ records, for queue-based activity, and the WTAS record for task related requests (commit, backout) and each record type  includes the range of CF requests that may be used to fulfill the MQ API request. We had to  focus on queue activity for this investigation.</p> <p>13) Don't feel daunted by the volume and complexity of the task related data, it can be  overwhelming when you first look at it. Thought is required to determine just how to  consolidate the data into useful information that can be used to make decisions about both  application and infrastructure patterns. It took several rounds of SQL attempts to get data in a  usable form with the information we were looking for, and we work with this kind of data  regularly.</p>"}]}